<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/calculations_and_plots/manage_timeseries.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/calculations_and_plots/manage_timeseries.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Manage timeseries data for all models at all defined points.&#10;&#10;This module handles:&#10;- Loading timeseries from saved NetCDF files&#10;- Reading fresh data if files don't exist&#10;- Saving timeseries for future reuse&#10;- Computing and saving timeseries for all points and models&#10;&#10;Functions are imported and used by plot_vertical_profiles.py and plot_cap_height.py&#10;to ensure consistent data handling.&#10;&quot;&quot;&quot;&#10;from __future__ import annotations&#10;&#10;import os&#10;from typing import List&#10;&#10;import xarray as xr&#10;&#10;import confg&#10;import read_icon_model_3D&#10;import read_in_arome&#10;import read_ukmo&#10;import read_wrf_helen&#10;from calculations_and_plots.calc_vhd import read_dems_calc_pcgp&#10;&#10;# Variables needed for all models&#10;variables = [&quot;udir&quot;, &quot;wspd&quot;, &quot;q&quot;, &quot;p&quot;, &quot;th&quot;, &quot;temp&quot;, &quot;rho&quot;, &quot;z&quot;, &quot;z_unstag&quot;]&#10;&#10;# Model processing order&#10;MODEL_ORDER = [&quot;AROME&quot;, &quot;ICON&quot;, &quot;ICON2TE&quot;, &quot;UM&quot;, &quot;WRF&quot;]&#10;&#10;&#10;def get_timeseries_path(model: str, point_name: str, height_as_z_coord: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Build the file path to a saved timeseries NetCDF file for a specific model and point.&#10;    &#10;    The timeseries files are stored with the naming convention:&#10;    MODEL_FOLDER/timeseries/modelname_pointname_timeseries_height_as_z.nc&#10;    &#10;    Note: Whitespaces in point_name are automatically replaced with underscores to avoid&#10;    filename issues.&#10;&#10;    Args:&#10;        model: Name of the weather model (AROME, ICON, ICON2TE, UM, WRF)&#10;        point_name: Name of the point location (from confg.py) - spaces will be replaced with &quot;_&quot;&#10;        height_as_z_coord: Height coordinate system identifier&#10;&#10;    Returns:&#10;        Full path to the timeseries file&#10;    &quot;&quot;&quot;&#10;    # Get the base directory for each model&#10;    if model == &quot;AROME&quot;:&#10;        base = confg.dir_AROME&#10;    elif model == &quot;ICON&quot;:&#10;        base = confg.icon_folder_3D&#10;    elif model == &quot;ICON2TE&quot;:&#10;        base = confg.icon2TE_folder_3D&#10;    elif model == &quot;UM&quot;:&#10;        base = confg.ukmo_folder&#10;    elif model == &quot;WRF&quot;:&#10;        base = confg.wrf_folder&#10;    else:&#10;        return &quot;&quot;&#10;&#10;    # Construct the filename with lowercase model name&#10;    model_name_lower = model.lower()&#10;    if model == &quot;ICON2TE&quot;:&#10;        model_name_lower = &quot;icon2te&quot;&#10;&#10;    # Remove whitespaces from point_name to avoid filename issues&#10;    point_name_safe = point_name.replace(&quot; &quot;, &quot;_&quot;)&#10;    &#10;    # Use os.path.normpath to ensure consistent path separators&#10;    filepath = os.path.join(base, &quot;timeseries&quot;, f&quot;{model_name_lower}_{point_name_safe}_timeseries_{height_as_z_coord}.nc&quot;)&#10;    return os.path.normpath(filepath)&#10;&#10;&#10;def save_timeseries(ds: xr.Dataset, model: str, point_name: str, height_as_z_coord: str) -&gt; None:&#10;    &quot;&quot;&quot;&#10;    Save a timeseries dataset to a NetCDF file for future reuse.&#10;    &#10;    Only saves if the file doesn't already exist to avoid overwriting and permission issues.&#10;    Creates the necessary directory structure if it doesn't exist.&#10;    &#10;    Args:&#10;        ds: xarray Dataset containing the timeseries data&#10;        model: Name of the weather model&#10;        point_name: Name of the point location&#10;    &quot;&quot;&quot;&#10;    timeseries_path = get_timeseries_path(model=model, point_name=point_name, height_as_z_coord=height_as_z_coord)&#10;&#10;    # Create the directory if it doesn't exist&#10;    os.makedirs(os.path.dirname(timeseries_path), exist_ok=True)&#10;&#10;    # Only save if the file doesn't already exist&#10;    if not os.path.exists(timeseries_path):&#10;        print(f&quot;  Saving {model} timeseries for {point_name} to: {timeseries_path}&quot;)&#10;        try:&#10;            ds.to_netcdf(timeseries_path)&#10;            print(f&quot;  ✓ Successfully saved {model} timeseries&quot;)&#10;        except Exception as e:&#10;            print(f&quot;  ✗ Warning: Could not save timeseries file {timeseries_path}: {e}&quot;)&#10;    else:&#10;        print(f&quot;  ℹ Timeseries file already exists, skipping save: {os.path.basename(timeseries_path)}&quot;)&#10;&#10;&#10;def load_timeseries(model: str, point_name: str, height_as_z_coord: str) -&gt; xr.Dataset | None:&#10;    &quot;&quot;&quot;&#10;    Load timeseries from saved NetCDF file.&#10;    &#10;    Args:&#10;        model: Name of the weather model&#10;        point_name: Name of the point location&#10;    &#10;    Returns:&#10;        xarray Dataset with timeseries data, or None if file doesn't exist&#10;    &quot;&quot;&quot;&#10;    timeseries_path = get_timeseries_path(model, point_name, height_as_z_coord=height_as_z_coord)&#10;&#10;    if os.path.exists(timeseries_path):&#10;        print(f&quot;  Loading {model} from saved timeseries: {os.path.basename(timeseries_path)}&quot;)&#10;        try:&#10;            ds = xr.open_dataset(timeseries_path)&#10;            return ds&#10;        except Exception as e:&#10;            print(f&quot;  ✗ Warning: Could not load saved file. Error: {e}&quot;)&#10;            return None&#10;&#10;    return None&#10;&#10;&#10;def read_fresh_timeseries(model: str, point: dict, point_name: str, variables_list: list,&#10;        height_as_z_coord: str = &quot;above_terrain&quot;) -&gt; xr.Dataset | None:&#10;    &quot;&quot;&quot;&#10;    Read fresh timeseries data from model output files.&#10;    &#10;    Uses PCGP (Physically Consistent Grid Point) selection for accurate point representation.&#10;    &#10;    Args:&#10;        model: Name of the weather model&#10;        point: Dictionary with 'lat' and 'lon' keys&#10;        point_name: Name of the point location&#10;        variables_list: List of variable names to read&#10;        height_as_z_coord: Whether to use height as z-coordinate&#10;    &#10;    Returns:&#10;        xarray Dataset with fresh timeseries data, or None if reading fails&#10;    &quot;&quot;&quot;&#10;    print(f&quot;  Reading fresh {model} data for {point_name}...&quot;)&#10;&#10;    try:&#10;        # Get PCGP for accurate point representation&#10;        pcgp_arome, pcgp_icon, pcgp_um, pcgp_wrf = read_dems_calc_pcgp(lat=point[&quot;lat&quot;], lon=point[&quot;lon&quot;])&#10;&#10;        # AROME &amp; UM aren't staggered -&gt; remove z_unstag if present&#10;        variables_for_reading = [v for v in variables_list if not (model in [&quot;AROME&quot;, &quot;UM&quot;] and v == &quot;z_unstag&quot;)]&#10;&#10;        # Map model to appropriate read function and PCGP&#10;        read_functions = {&quot;AROME&quot;: (read_in_arome.read_in_arome_fixed_point, pcgp_arome, {}),&#10;                          &quot;ICON&quot;: (read_icon_model_3D.read_icon_fixed_point, pcgp_icon, {&quot;variant&quot;: &quot;ICON&quot;}),&#10;                          &quot;ICON2TE&quot;: (read_icon_model_3D.read_icon_fixed_point, pcgp_icon, {&quot;variant&quot;: &quot;ICON2TE&quot;}),&#10;                          &quot;UM&quot;: (read_ukmo.read_ukmo_fixed_point, pcgp_um, {}),&#10;                          &quot;WRF&quot;: (read_wrf_helen.read_wrf_fixed_point, pcgp_wrf, {})}&#10;&#10;        if model not in read_functions:&#10;            print(f&quot;  ✗ Unknown model: {model}&quot;)&#10;            return None&#10;&#10;        read_func, pcgp, extra_kwargs = read_functions[model]&#10;        ds = read_func(lat=pcgp.y.values, lon=pcgp.x.values, variables=variables_for_reading,&#10;                       height_as_z_coord=height_as_z_coord, **extra_kwargs)&#10;&#10;        return ds&#10;&#10;    except Exception as e:&#10;        print(f&quot;  ✗ Error reading fresh data for {model} at {point_name}: {e}&quot;)&#10;        return None&#10;&#10;&#10;def load_or_read_timeseries(model: str, point: dict, point_name: str, variables_list: list = variables,&#10;        height_as_z_coord: str = &quot;above_terrain&quot;) -&gt; xr.Dataset | None:&#10;    &quot;&quot;&quot;&#10;    Load timeseries from saved file if it exists, otherwise read fresh data and save it.&#10;    &#10;    This function implements the core logic for efficient data loading:&#10;    1. Check if saved timeseries file exists&#10;    2. If yes: load from file&#10;    3. If no: read fresh data from model output and save for future use&#10;    &#10;    Args:&#10;        model: Name of the weather model (AROME, ICON, ICON2TE, UM, WRF)&#10;        point: Dictionary with 'lat' and 'lon' keys&#10;        point_name: Name of the point location (from confg.py)&#10;        variables_list: List of variable names to read (default: uses global variables list)&#10;        height_as_z_coord: same as in read in functions...&#10;    &#10;    Returns:&#10;        xarray Dataset with timeseries data, or None if loading/reading fails&#10;    &quot;&quot;&quot;&#10;&#10;    # Try to load from saved file first, if not returns None...&#10;    ds = load_timeseries(model=model, point_name=point_name, height_as_z_coord=height_as_z_coord)&#10;    if ds is not None:&#10;        return ds&#10;&#10;    # If no saved file exists, read fresh data&#10;    ds = read_fresh_timeseries(model=model, point=point, point_name=point_name, variables_list=variables_list,&#10;                               height_as_z_coord=height_as_z_coord)&#10;    if ds is not None:&#10;        # Save the freshly read data for future use&#10;        save_timeseries(ds=ds, model=model, point_name=point_name, height_as_z_coord=height_as_z_coord)&#10;&#10;    return ds&#10;&#10;&#10;def compute_and_save_all_timeseries(point_names: List[str] = confg.POINT_NAMES,&#10;        variables_list: list = variables, height_as_z_coord: str = &quot;above_terrain&quot;) -&gt; None:&#10;    &quot;&quot;&quot;&#10;    Compute and save timeseries for all models at all specified points.&#10;    &#10;    This is the main function to pre-compute and save timeseries data for later use&#10;    by plotting and analysis scripts.&#10;    &#10;    Args:&#10;        point_names: List of point names from confg.py (default: ALL_POINTS from confg)&#10;        variables_list: List of variable names to read (default: uses global variables list)&#10;        height_as_z_coord: As in read in functions: How to set the vertical coordinate:&#10;            - &quot;direct&quot;: Use geopotential height and set it directly as vertical coord.&#10;            - &quot;above_terrain&quot;: Height above terrain at this point (default)&#10;            - False/None: Keep original model level indexing&#10;    &quot;&quot;&quot;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;Computing and saving timeseries for {len(MODEL_ORDER)} models at {len(point_names)} points&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;&#10;    total_computed = 0&#10;    total_skipped = 0&#10;&#10;    for point_name in point_names:&#10;        point = confg.ALL_POINTS[point_name]  # index dict for that point&#10;        if point is None:&#10;            print(f&quot;⚠ Skipping {point_name} - not found in confg&quot;)&#10;            continue&#10;&#10;        print(f&quot;\n{'-' * 70}&quot;)&#10;        print(f&quot;Processing: {point['name']} ({point_name})&quot;)&#10;        print(f&quot;{'-' * 70}&quot;)&#10;&#10;        for model in MODEL_ORDER:&#10;            # Check if file already exists&#10;            timeseries_path = get_timeseries_path(model, point_name, height_as_z_coord)&#10;            if os.path.exists(timeseries_path):&#10;                print(f&quot;  {model}: Already exists, skipping&quot;)&#10;                total_skipped += 1&#10;                continue&#10;&#10;            # Read and save timeseries&#10;            print(f&quot;  {model}: Computing timeseries...&quot;)&#10;            ds = read_fresh_timeseries(model, point, point_name, variables_list, height_as_z_coord)&#10;&#10;            if ds is not None:&#10;                save_timeseries(ds, model, point_name, height_as_z_coord)&#10;                ds.close()&#10;                print(f&quot;  {model}: ✓ Success&quot;)&#10;                total_computed += 1&#10;            else:&#10;                print(f&quot;  {model}: ✗ Failed&quot;)&#10;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;✓ Timeseries computation complete!&quot;)&#10;    print(f&quot;  Computed: {total_computed}&quot;)&#10;    print(f&quot;  Skipped (already exist): {total_skipped}&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Compute and save timeseries for all points and all models&#10;    compute_and_save_all_timeseries()" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Manage timeseries data for all models at all defined points.&#10;&#10;This module handles:&#10;- Loading timeseries from saved NetCDF files&#10;- Reading fresh data if files don't exist&#10;- Saving timeseries for future reuse&#10;- Computing and saving timeseries for all points and models&#10;&#10;Functions are imported and used by plot_vertical_profiles.py and plot_cap_height.py&#10;to ensure consistent data handling.&#10;&quot;&quot;&quot;&#10;from __future__ import annotations&#10;&#10;import os&#10;from typing import List&#10;&#10;import xarray as xr&#10;&#10;import confg&#10;import read_icon_model_3D&#10;import read_in_arome&#10;import read_ukmo&#10;import read_wrf_helen&#10;from calculations_and_plots.calc_vhd import read_dems_calc_pcgp&#10;&#10;# Variables needed for all models&#10;variables = [&quot;udir&quot;, &quot;wspd&quot;, &quot;q&quot;, &quot;p&quot;, &quot;th&quot;, &quot;temp&quot;, &quot;rho&quot;, &quot;z&quot;, &quot;z_unstag&quot;]&#10;&#10;# Model processing order&#10;MODEL_ORDER = [&quot;AROME&quot;, &quot;ICON&quot;, &quot;ICON2TE&quot;, &quot;UM&quot;, &quot;WRF&quot;]&#10;&#10;&#10;def get_timeseries_path(model: str, point_name: str, height_as_z_coord: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Build the file path to a saved timeseries NetCDF file for a specific model and point.&#10;    &#10;    The timeseries files are stored with the naming convention:&#10;    MODEL_FOLDER/timeseries/modelname_pointname_timeseries_height_as_z.nc&#10;    &#10;    Note: Whitespaces in point_name are automatically replaced with underscores to avoid&#10;    filename issues.&#10;&#10;    Args:&#10;        model: Name of the weather model (AROME, ICON, ICON2TE, UM, WRF)&#10;        point_name: Name of the point location (from confg.py) - spaces will be replaced with &quot;_&quot;&#10;        height_as_z_coord: Height coordinate system identifier&#10;&#10;    Returns:&#10;        Full path to the timeseries file&#10;    &quot;&quot;&quot;&#10;    # Get the base directory for each model&#10;    if model == &quot;AROME&quot;:&#10;        base = confg.dir_AROME&#10;    elif model == &quot;ICON&quot;:&#10;        base = confg.icon_folder_3D&#10;    elif model == &quot;ICON2TE&quot;:&#10;        base = confg.icon2TE_folder_3D&#10;    elif model == &quot;UM&quot;:&#10;        base = confg.ukmo_folder&#10;    elif model == &quot;WRF&quot;:&#10;        base = confg.wrf_folder&#10;    else:&#10;        return &quot;&quot;&#10;&#10;    # Construct the filename with lowercase model name&#10;    model_name_lower = model.lower()&#10;    if model == &quot;ICON2TE&quot;:&#10;        model_name_lower = &quot;icon2te&quot;&#10;&#10;    # Remove whitespaces from point_name to avoid filename issues&#10;    point_name_safe = point_name.replace(&quot; &quot;, &quot;_&quot;)&#10;    &#10;    # Use os.path.normpath to ensure consistent path separators&#10;    filepath = os.path.join(base, &quot;timeseries&quot;, f&quot;{model_name_lower}_{point_name_safe}_timeseries_{height_as_z_coord}.nc&quot;)&#10;    return os.path.normpath(filepath)&#10;&#10;&#10;def save_timeseries(ds: xr.Dataset, model: str, point_name: str, height_as_z_coord: str) -&gt; None:&#10;    &quot;&quot;&quot;&#10;    Save a timeseries dataset to a NetCDF file for future reuse.&#10;    &#10;    Only saves if the file doesn't already exist to avoid overwriting and permission issues.&#10;    Creates the necessary directory structure if it doesn't exist.&#10;    &#10;    Args:&#10;        ds: xarray Dataset containing the timeseries data&#10;        model: Name of the weather model&#10;        point_name: Name of the point location&#10;    &quot;&quot;&quot;&#10;    timeseries_path = get_timeseries_path(model=model, point_name=point_name, height_as_z_coord=height_as_z_coord)&#10;&#10;    # Create the directory if it doesn't exist&#10;    os.makedirs(os.path.dirname(timeseries_path), exist_ok=True)&#10;&#10;    # Only save if the file doesn't already exist&#10;    if not os.path.exists(timeseries_path):&#10;        print(f&quot;  Saving {model} timeseries for {point_name} to: {timeseries_path}&quot;)&#10;        try:&#10;            ds.to_netcdf(timeseries_path)&#10;            print(f&quot;  ✓ Successfully saved {model} timeseries&quot;)&#10;        except Exception as e:&#10;            print(f&quot;  ✗ Warning: Could not save timeseries file {timeseries_path}: {e}&quot;)&#10;    else:&#10;        print(f&quot;  ℹ Timeseries file already exists, skipping save: {os.path.basename(timeseries_path)}&quot;)&#10;&#10;&#10;def load_timeseries(model: str, point_name: str, height_as_z_coord: str) -&gt; xr.Dataset | None:&#10;    &quot;&quot;&quot;&#10;    Load timeseries from saved NetCDF file.&#10;    &#10;    Args:&#10;        model: Name of the weather model&#10;        point_name: Name of the point location&#10;    &#10;    Returns:&#10;        xarray Dataset with timeseries data, or None if file doesn't exist&#10;    &quot;&quot;&quot;&#10;    timeseries_path = get_timeseries_path(model, point_name, height_as_z_coord=height_as_z_coord)&#10;&#10;    if os.path.exists(timeseries_path):&#10;        print(f&quot;  Loading {model} from saved timeseries: {os.path.basename(timeseries_path)}&quot;)&#10;        try:&#10;            ds = xr.open_dataset(timeseries_path)&#10;            return ds&#10;        except Exception as e:&#10;            print(f&quot;  ✗ Warning: Could not load saved file. Error: {e}&quot;)&#10;            return None&#10;&#10;    return None&#10;&#10;&#10;def read_fresh_timeseries(model: str, point: dict, point_name: str, variables_list: list,&#10;        height_as_z_coord: str = &quot;above_terrain&quot;) -&gt; xr.Dataset | None:&#10;    &quot;&quot;&quot;&#10;    Read fresh timeseries data from model output files.&#10;    &#10;    Uses PCGP (Physically Consistent Grid Point) selection for accurate point representation.&#10;    &#10;    Args:&#10;        model: Name of the weather model&#10;        point: Dictionary with 'lat' and 'lon' keys&#10;        point_name: Name of the point location&#10;        variables_list: List of variable names to read&#10;        height_as_z_coord: Whether to use height as z-coordinate&#10;    &#10;    Returns:&#10;        xarray Dataset with fresh timeseries data, or None if reading fails&#10;    &quot;&quot;&quot;&#10;    print(f&quot;  Reading fresh {model} data for {point_name}...&quot;)&#10;&#10;    try:&#10;        # Get PCGP for accurate point representation&#10;        pcgp_arome, pcgp_icon, pcgp_um, pcgp_wrf = read_dems_calc_pcgp(lat=point[&quot;lat&quot;], lon=point[&quot;lon&quot;])&#10;&#10;        # AROME &amp; UM aren't staggered -&gt; remove z_unstag if present&#10;        variables_for_reading = [v for v in variables_list if not (model in [&quot;AROME&quot;, &quot;UM&quot;] and v == &quot;z_unstag&quot;)]&#10;&#10;        # Map model to appropriate read function and PCGP&#10;        read_functions = {&quot;AROME&quot;: (read_in_arome.read_in_arome_fixed_point, pcgp_arome, {}),&#10;                          &quot;ICON&quot;: (read_icon_model_3D.read_icon_fixed_point, pcgp_icon, {&quot;variant&quot;: &quot;ICON&quot;}),&#10;                          &quot;ICON2TE&quot;: (read_icon_model_3D.read_icon_fixed_point, pcgp_icon, {&quot;variant&quot;: &quot;ICON2TE&quot;}),&#10;                          &quot;UM&quot;: (read_ukmo.read_ukmo_fixed_point, pcgp_um, {}),&#10;                          &quot;WRF&quot;: (read_wrf_helen.read_wrf_fixed_point, pcgp_wrf, {})}&#10;&#10;        if model not in read_functions:&#10;            print(f&quot;  ✗ Unknown model: {model}&quot;)&#10;            return None&#10;&#10;        read_func, pcgp, extra_kwargs = read_functions[model]&#10;        ds = read_func(lat=pcgp.y.values, lon=pcgp.x.values, variables=variables_for_reading,&#10;                       height_as_z_coord=height_as_z_coord, **extra_kwargs)&#10;&#10;        return ds&#10;&#10;    except Exception as e:&#10;        print(f&quot;  ✗ Error reading fresh data for {model} at {point_name}: {e}&quot;)&#10;        return None&#10;&#10;&#10;def load_or_read_timeseries(model: str, point: dict, point_name: str, variables_list: list = variables,&#10;        height_as_z_coord: str = &quot;above_terrain&quot;) -&gt; xr.Dataset | None:&#10;    &quot;&quot;&quot;&#10;    Load timeseries from saved file if it exists, otherwise read fresh data and save it.&#10;    &#10;    This function implements the core logic for efficient data loading:&#10;    1. Check if saved timeseries file exists&#10;    2. If yes: load from file&#10;    3. If no: read fresh data from model output and save for future use&#10;    &#10;    Args:&#10;        model: Name of the weather model (AROME, ICON, ICON2TE, UM, WRF)&#10;        point: Dictionary with 'lat' and 'lon' keys&#10;        point_name: Name of the point location (from confg.py)&#10;        variables_list: List of variable names to read (default: uses global variables list)&#10;        height_as_z_coord: same as in read in functions...&#10;    &#10;    Returns:&#10;        xarray Dataset with timeseries data, or None if loading/reading fails&#10;    &quot;&quot;&quot;&#10;&#10;    # Try to load from saved file first, if not returns None...&#10;    ds = load_timeseries(model=model, point_name=point_name, height_as_z_coord=height_as_z_coord)&#10;    if ds is not None:&#10;        return ds&#10;&#10;    # If no saved file exists, read fresh data&#10;    ds = read_fresh_timeseries(model=model, point=point, point_name=point_name, variables_list=variables_list,&#10;                               height_as_z_coord=height_as_z_coord)&#10;    if ds is not None:&#10;        # Save the freshly read data for future use&#10;        save_timeseries(ds=ds, model=model, point_name=point_name, height_as_z_coord=height_as_z_coord)&#10;&#10;    return ds&#10;&#10;&#10;def compute_and_save_all_timeseries(point_names: List[str] = confg.POINT_NAMES,&#10;        variables_list: list = variables, height_as_z_coord: str = &quot;above_terrain&quot;) -&gt; None:&#10;    &quot;&quot;&quot;&#10;    Compute and save timeseries for all models at all specified points.&#10;    &#10;    This is the main function to pre-compute and save timeseries data for later use&#10;    by plotting and analysis scripts.&#10;    &#10;    Args:&#10;        point_names: List of point names from confg.py (default: ALL_POINTS from confg)&#10;        variables_list: List of variable names to read (default: uses global variables list)&#10;        height_as_z_coord: As in read in functions: How to set the vertical coordinate:&#10;            - &quot;direct&quot;: Use geopotential height and set it directly as vertical coord.&#10;            - &quot;above_terrain&quot;: Height above terrain at this point (default)&#10;            - False/None: Keep original model level indexing&#10;    &quot;&quot;&quot;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;Computing and saving timeseries for {len(MODEL_ORDER)} models at {len(point_names)} points&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;&#10;    total_computed = 0&#10;    total_skipped = 0&#10;&#10;    for point_name in point_names:&#10;        point = confg.ALL_POINTS[point_name]  # index dict for that point&#10;        if point is None:&#10;            print(f&quot;⚠ Skipping {point_name} - not found in confg&quot;)&#10;            continue&#10;&#10;        print(f&quot;\n{'-' * 70}&quot;)&#10;        print(f&quot;Processing: {point['name']} ({point_name})&quot;)&#10;        print(f&quot;{'-' * 70}&quot;)&#10;&#10;        for model in MODEL_ORDER:&#10;            # Check if file already exists&#10;            timeseries_path = get_timeseries_path(model, point_name, height_as_z_coord)&#10;            if os.path.exists(timeseries_path):&#10;                print(f&quot;  {model}: Already exists, skipping&quot;)&#10;                total_skipped += 1&#10;                continue&#10;&#10;            # Read and save timeseries&#10;            print(f&quot;  {model}: Computing timeseries...&quot;)&#10;            ds = read_fresh_timeseries(model, point, point_name, variables_list, height_as_z_coord)&#10;&#10;            if ds is not None:&#10;                save_timeseries(ds, model, point_name, height_as_z_coord)&#10;                ds.close()&#10;                print(f&quot;  {model}: ✓ Success&quot;)&#10;                total_computed += 1&#10;            else:&#10;                print(f&quot;  {model}: ✗ Failed&quot;)&#10;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;✓ Timeseries computation complete!&quot;)&#10;    print(f&quot;  Computed: {total_computed}&quot;)&#10;    print(f&quot;  Skipped (already exist): {total_skipped}&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Compute and save timeseries for all points and all models&#10;    compute_and_save_all_timeseries()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/calculations_and_plots/plot_vertical_profiles.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/calculations_and_plots/plot_vertical_profiles.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Plot vertical temperature profiles for all models at fixed points.&#10;&#10;This module creates interactive plots showing temperature profiles with height for different&#10;weather models (AROME, ICON, ICON2TE, UM, WRF) and observations (Radiosonde, HATPRO)&#10;at various locations. The plots include CAP (Cold Air Pool) height markers when available.&#10;&#10;Main functionality:&#10;- Load timeseries data from saved files (or read fresh data if not available)&#10;- Add radiosonde and HATPRO observations for Innsbruck points&#10;- Create small multiples plots showing all points side-by-side&#10;- Save interactive HTML plots&#10;&quot;&quot;&quot;&#10;from __future__ import annotations&#10;&#10;# Fix for OpenMP duplicate library error on Windows&#10;import os&#10;os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'&#10;&#10;import os&#10;from typing import List&#10;&#10;import numpy as np&#10;import pandas as pd&#10;import plotly.graph_objects as go&#10;import xarray as xr&#10;&#10;from plotly.subplots import make_subplots&#10;&#10;import confg&#10;from confg import model_colors_temp_wind, model_colors_humidity, icon_2te_hatpro_linestyle&#10;from read_in_hatpro_radiosonde import read_radiosonde_dataset&#10;from calculations_and_plots.calc_cap_height import cap_height_profile&#10;# Import timeseries management functions&#10;from calculations_and_plots.manage_timeseries import (load_or_read_timeseries, MODEL_ORDER)&#10;&#10;&#10;&#10;&#10;# Observation data paths; is actually in confg!&#10;# RADIOSONDE_PATH = r&quot;D:\MSc_Arbeit\data\radiosonde_ibk_smoothed.nc&quot;&#10;# HATPRO_PATH = r&quot;D:\MSc_Arbeit\data\Observations\HATPRO_obs\hatpro_interpolated_arome_height_as_z.nc&quot;&#10;&#10;&#10;def get_obs_cap_path(obs_type: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Get the path to the computed CAP height file for observations.&#10;    &#10;    Args:&#10;        obs_type: Either &quot;radiosonde&quot; or &quot;hatpro&quot;&#10;    &#10;    Returns:&#10;        Full path to the CAP height NetCDF file&#10;    &quot;&quot;&quot;&#10;    import confg&#10;    cap_dir = os.path.join(confg.data_folder, &quot;calculated_cap_height&quot;)&#10;    return os.path.join(cap_dir, f&quot;{obs_type}_cap_height.nc&quot;)&#10;&#10;&#10;def _get_cap_height_value(cap_height_da: xr.DataArray, point: dict, ts: np.datetime64) -&gt; float:&#10;    &quot;&quot;&quot;&#10;    Extract CAP height value from DataArray, handling different dimension structures.&#10;    Returns NaN if extraction fails.&#10;    &quot;&quot;&quot;&#10;    if not cap_height_da.dims:&#10;        # Scalar value&#10;        return cap_height_da.item()&#10;&#10;    if &quot;lat&quot; in cap_height_da.dims and &quot;lon&quot; in cap_height_da.dims:&#10;        # Spatial + time dimensions&#10;        return cap_height_da.sel(lat=point[&quot;lat&quot;], lon=point[&quot;lon&quot;], time=ts).item()&#10;&#10;    # Only time dimension&#10;    return cap_height_da.sel(time=ts, method=&quot;nearest&quot;).item()&#10;&#10;&#10;def _load_or_compute_cap_heights(model: str, ds_filtered: xr.Dataset, point: dict, timestamps: List[str],&#10;                                 ts_array: List[np.datetime64], model_data: dict, max_height: float) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Compute CAP heights from timeseries (point) data.&#10;    Returns dict mapping timestamp strings to (temp_at_cap, cap_height) tuples (tuple is needed so that the&#10;    cap-marker is at the right temperature in the plot afterwards).&#10;    &quot;&quot;&quot;&#10;    cap_data = {}&#10;&#10;    ds_with_cap = cap_height_profile(ds_filtered, consecutive=3, model=model)&#10;    cap_height_da = ds_with_cap[&quot;cap_height&quot;]&#10;&#10;    # Extract CAP heights for each timestamp&#10;    for ts_str, ts in zip(timestamps, ts_array):&#10;        cap_height = _get_cap_height_value(cap_height_da, point, ts)&#10;&#10;        if np.isnan(cap_height) or cap_height &gt; max_height:&#10;            continue&#10;&#10;        if ts_str not in model_data[model]:&#10;            continue&#10;&#10;        temp_data, height_data = model_data[model][ts_str]&#10;        if len(height_data) == 0:&#10;            continue&#10;&#10;        idx = np.argmin(np.abs(height_data - cap_height))&#10;        temp_at_cap = temp_data[idx]&#10;        cap_data[ts_str] = (temp_at_cap, cap_height)&#10;&#10;    return cap_data&#10;&#10;&#10;def plot_single_point_with_slider(point_name: str, timestamps: List[str], max_height: float = 5000,&#10;                                  plot_max_height: float = 2000,&#10;                                  variables: list = [&quot;udir&quot;, &quot;wspd&quot;, &quot;q&quot;, &quot;p&quot;, &quot;th&quot;, &quot;temp&quot;, &quot;z&quot;,&#10;                                                     &quot;z_unstag&quot;]) -&gt; go.Figure:&#10;    &quot;&quot;&quot;&#10;    Create an interactive plot with time slider for a single point location.&#10;    &#10;    Users can slide through different timesteps and see the temperature profiles update dynamically.&#10;    The plot shows all models and observations at one location.&#10;    &#10;    Args:&#10;        point_name: Point location name from confg.py (e.g. &quot;ibk_villa&quot;)&#10;        timestamps: List of ISO format timestamp strings&#10;        max_height: Maximum height in meters to load data (default: 5000m)&#10;        plot_max_height: Maximum height in meters to display on y-axis (default: 2000m)&#10;    &#10;    Returns:&#10;        Plotly figure object with the interactive time slider&#10;    &quot;&quot;&quot;&#10;    point = confg.ALL_POINTS.get(point_name)&#10;    if point is None:&#10;        raise ValueError(f&quot;Point {point_name} not found in confg&quot;)&#10;&#10;    print(f&quot;Creating slider plot for {point['name']} with {len(timestamps)} timesteps...&quot;)&#10;&#10;    # Convert timestamp strings to numpy datetime64&#10;    ts_array = [np.datetime64(ts) for ts in timestamps]&#10;&#10;    # Pre-load all data for all timesteps&#10;    print(f&quot;  Loading data for all models and timesteps...&quot;)&#10;    model_data = {}  # {model: {timestamp: (temp, height)}}&#10;    model_humidity_data = {}  # {model: {timestamp: (q, height)}}&#10;    model_wspd_data = {}  # {model: {timestamp: (wspd, height)}}&#10;    model_udir_data = {}  # {model: {timestamp: (wdir, height)}}&#10;    obs_data = {}  # {obs_type: data}&#10;    cap_data = {}  # {model: {timestamp: (temp_at_cap, cap_height)}}&#10;&#10;    # Load model data&#10;    for model in MODEL_ORDER:&#10;        model_data[model] = {}&#10;        model_humidity_data[model] = {}&#10;        model_wspd_data[model] = {}&#10;        model_udir_data[model] = {}&#10;&#10;        # Load timeseries dataset, for model data&#10;        ds = load_or_read_timeseries(model=model, point=point, point_name=point_name, variables_list=variables,&#10;                                     height_as_z_coord=&quot;above_terrain&quot;)&#10;        if ds is None:&#10;            print(f&quot;    Warning: Could not load {model} data&quot;)&#10;            continue&#10;&#10;        # Get height variable&#10;        if &quot;height&quot; not in ds.coords:&#10;            print(f&quot;    Warning: No height coordinate found for {model}&quot;)&#10;            ds.close()&#10;            continue&#10;&#10;        height_var = ds.coords[&quot;height&quot;]&#10;        ds_filtered = ds.where(height_var &lt;= max_height, drop=True)&#10;&#10;        # Extract temperature and height values for each timestamp&#10;        for ts_str, ts in zip(timestamps, ts_array):&#10;            temp = ds_filtered[&quot;temp&quot;].sel(time=ts).values&#10;            height = ds_filtered.coords[&quot;height&quot;].values&#10;&#10;            # Filter NaNs for temperature&#10;            valid = ~np.isnan(temp) &amp; ~np.isnan(height)&#10;            model_data[model][ts_str] = (temp[valid], height[valid])&#10;&#10;            # Extract humidity data (q) if available&#10;            if &quot;q&quot; in ds_filtered:&#10;                q = ds_filtered[&quot;q&quot;].sel(time=ts).values&#10;                # Convert from kg/kg to g/kg&#10;                q = q * 1000&#10;                # Filter NaNs for humidity&#10;                valid_q = ~np.isnan(q) &amp; ~np.isnan(height)&#10;                model_humidity_data[model][ts_str] = (q[valid_q], height[valid_q])&#10;&#10;            # Extract wind speed data (wspd) if available&#10;            if &quot;wspd&quot; in ds_filtered:&#10;                wspd = ds_filtered[&quot;wspd&quot;].sel(time=ts).values&#10;                valid_wspd = ~np.isnan(wspd) &amp; ~np.isnan(height)&#10;                model_wspd_data[model][ts_str] = (wspd[valid_wspd], height[valid_wspd])&#10;&#10;            # Extract wind direction data (udir) if available&#10;            if &quot;udir&quot; in ds_filtered:&#10;                udir = ds_filtered[&quot;udir&quot;].sel(time=ts).values&#10;                valid_udir = ~np.isnan(udir) &amp; ~np.isnan(height)&#10;                model_udir_data[model][ts_str] = (udir[valid_udir], height[valid_udir])&#10;&#10;        # Load or compute CAP heights&#10;        try:&#10;            cap_data[model] = _load_or_compute_cap_heights(model, ds_filtered, point, timestamps, ts_array, model_data,&#10;                                                           max_height)&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Could not load/compute CAP height for {model}: {e}&quot;)&#10;&#10;        ds.close()&#10;&#10;    # Load observation data (only for Innsbruck points)&#10;    if point_name.startswith(&quot;ibk&quot;):&#10;        # Radiosonde (no time dimension)&#10;        try:&#10;            ds_radiosonde = read_radiosonde_dataset(height_as_z_coord=&quot;above_terrain&quot;)&#10;            ds_filtered = ds_radiosonde.where(ds_radiosonde[&quot;height&quot;] &lt;= max_height, drop=True)&#10;            temp = ds_filtered[&quot;temp&quot;].values&#10;            height = ds_filtered[&quot;height&quot;].values&#10;            valid = ~np.isnan(temp) &amp; ~np.isnan(height)&#10;            obs_data[&quot;radiosonde&quot;] = (temp[valid], height[valid])&#10;&#10;            # Extract humidity data (q) if available&#10;            if &quot;q&quot; in ds_filtered:&#10;                q = ds_filtered[&quot;q&quot;].values  # in kg/kg&#10;                # Convert from kg/kg to g/kg&#10;                q = q * 1000&#10;                valid_q = ~np.isnan(q) &amp; ~np.isnan(height)  # filter NaNs ...&#10;                obs_data[&quot;radiosonde_humidity&quot;] = (q[valid_q], height[valid_q])&#10;&#10;            # Extract wind speed data (wspd) if available&#10;            if &quot;wspd&quot; in ds_filtered:&#10;                wspd = ds_filtered[&quot;wspd&quot;].values&#10;                valid_wspd = ~np.isnan(wspd) &amp; ~np.isnan(height)&#10;                obs_data[&quot;radiosonde_wspd&quot;] = (wspd[valid_wspd], height[valid_wspd])&#10;&#10;            # Extract wind direction data (udir) if available&#10;            if &quot;udir&quot; in ds_filtered:&#10;                udir = ds_filtered[&quot;udir&quot;].values&#10;                valid_udir = ~np.isnan(udir) &amp; ~np.isnan(height)&#10;                obs_data[&quot;radiosonde_udir&quot;] = (udir[valid_udir], height[valid_udir])&#10;&#10;            # Radiosonde CAP height was searched in plot and defined in confg&#10;            if not np.isnan(confg.radiosonde_cap_height) and confg.radiosonde_cap_height &lt;= max_height:&#10;                idx = np.argmin(np.abs(height[valid] - confg.radiosonde_cap_height))&#10;                obs_data[&quot;radiosonde_cap&quot;] = (temp[valid][idx], confg.radiosonde_cap_height)&#10;&#10;            ds_radiosonde.close()&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Error in loading Radiosonde: {e}&quot;)&#10;&#10;        # SL88 LIDAR (time-dependent wind data)&#10;        try:&#10;            if os.path.exists(confg.lidar_sl88_merged_path):&#10;                print(f&quot;    Loading SL88 LIDAR data&quot;)&#10;                ds_lidar = xr.open_dataset(confg.lidar_sl88_merged_path)&#10;&#10;                obs_data[&quot;lidar_wspd&quot;] = {}&#10;                obs_data[&quot;lidar_udir&quot;] = {}&#10;&#10;                for ts_str, ts in zip(timestamps, ts_array):&#10;                    # Select nearest time&#10;                    ds_ts = ds_lidar.sel(time=ts, method='nearest', tolerance='3min')&#10;&#10;                    # Get height values in meters (from height_m coordinate)&#10;                    if 'height_m' in ds_ts.coords:&#10;                        height = ds_ts['height_m'].values&#10;                    else:&#10;                        print(f&quot;    Warning: No height_m coordinate in SL88 LIDAR data&quot;)&#10;                        continue&#10;&#10;                    # Filter to max_height&#10;                    height_mask = height &lt;= max_height&#10;                    height_filtered = height[height_mask]&#10;&#10;                    # Extract wind speed (ff variable)&#10;                    if 'ff' in ds_ts:&#10;                        wspd = ds_ts['ff'].values&#10;                        wspd_filtered = wspd[height_mask]&#10;                        valid_wspd = ~np.isnan(wspd_filtered) &amp; ~np.isnan(height_filtered)&#10;                        obs_data[&quot;lidar_wspd&quot;][ts_str] = (wspd_filtered[valid_wspd], height_filtered[valid_wspd])&#10;&#10;                    # Extract wind direction (dd variable)&#10;                    if 'dd' in ds_ts:&#10;                        wdir = ds_ts['dd'].values&#10;                        wdir_filtered = wdir[height_mask]&#10;                        valid_wdir = ~np.isnan(wdir_filtered) &amp; ~np.isnan(height_filtered)&#10;                        obs_data[&quot;lidar_udir&quot;][ts_str] = (wdir_filtered[valid_wdir], height_filtered[valid_wdir])&#10;&#10;                ds_lidar.close()&#10;                print(f&quot;    ✓ SL88 LIDAR data loaded successfully&quot;)&#10;            else:&#10;                print(f&quot;    Warning: SL88 LIDAR merged file not found at {confg.lidar_sl88_merged_path}&quot;)&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Error in loading SL88 LIDAR: {e}&quot;)&#10;&#10;        # HATPRO (time-dependent)&#10;        try:&#10;            # Check for HATPRO file with CAP height first&#10;            if os.path.exists(confg.hatpro_with_cap_height):&#10;                # Load HATPRO data with pre-computed CAP height&#10;                print(f&quot;    Loading HATPRO data with CAP height&quot;)&#10;                ds_hatpro = xr.open_dataset(confg.hatpro_with_cap_height)&#10;                hatpro_cap_da = ds_hatpro[&quot;cap_height&quot;]&#10;&#10;            elif os.path.exists(confg.hatpro_calced_vars):  # used interpolated heights to arome levels -&gt; change to&#10;                # smooth HATPRO!&#10;                # Load original HATPRO data and compute CAP height&#10;                print(f&quot;    Loading HATPRO data&quot;)&#10;                ds_hatpro = xr.open_dataset(confg.hatpro_calced_vars)&#10;&#10;                print(f&quot;    Computing CAP height for HATPRO...&quot;)&#10;                # Filter to max_height before computing CAP&#10;                ds_hatpro_filtered = ds_hatpro.where(ds_hatpro[&quot;height&quot;] &lt;= max_height, drop=True)&#10;                ds_hatpro_with_cap = cap_height_profile(ds_hatpro_filtered, consecutive=3, model=&quot;HATPRO&quot;)&#10;&#10;                # Add CAP height to original (non-filtered) dataset&#10;                ds_hatpro[&quot;cap_height&quot;] = ds_hatpro_with_cap[&quot;cap_height&quot;]&#10;                hatpro_cap_da = ds_hatpro[&quot;cap_height&quot;]&#10;&#10;                # Save complete dataset with CAP height&#10;                print(f&quot;    Saving HATPRO dataset with CAP height to {confg.hatpro_with_cap_height}&quot;)&#10;                ds_hatpro.to_netcdf(confg.hatpro_with_cap_height)&#10;                print(f&quot;    ✓ Saved successfully&quot;)&#10;            else:&#10;                print(f&quot;    Warning: HATPRO file not found&quot;)&#10;                ds_hatpro = None&#10;                hatpro_cap_da = None&#10;&#10;            if ds_hatpro is not None:&#10;                obs_data[&quot;hatpro&quot;] = {}&#10;                obs_data[&quot;hatpro_humidity&quot;] = {}&#10;                obs_data[&quot;hatpro_wspd&quot;] = {}&#10;                obs_data[&quot;hatpro_udir&quot;] = {}&#10;&#10;                for ts_str, ts in zip(timestamps, ts_array):&#10;                    ds_ts = ds_hatpro.sel(time=ts)&#10;                    ds_filtered = ds_ts.where(ds_ts[&quot;height&quot;] &lt;= max_height, drop=True)&#10;&#10;                    temp = ds_filtered[&quot;temp&quot;].values&#10;                    height = ds_filtered[&quot;height&quot;].values&#10;                    valid = ~np.isnan(temp) &amp; ~np.isnan(height)&#10;                    obs_data[&quot;hatpro&quot;][ts_str] = (temp[valid], height[valid])&#10;                    # creates large dict w. radiosonde w. cap_height &amp; hatpro data for that timestamp&#10;&#10;                    # Extract humidity data (q) if available; wind data isn't available -&gt; maybe include LIDAR?&#10;                    if &quot;q&quot; in ds_filtered:&#10;                        q = ds_filtered[&quot;q&quot;].values  # in kg/kg&#10;                        # Convert from kg/kg to g/kg&#10;                        q = q * 1000&#10;                        valid_q = ~np.isnan(q) &amp; ~np.isnan(height)  # filter NaNs ...&#10;                        obs_data[&quot;hatpro_humidity&quot;][ts_str] = (q[valid_q], height[valid_q])&#10;&#10;                    # CAP height&#10;                    if hatpro_cap_da is not None:&#10;                        cap_height = hatpro_cap_da.sel(time=ts, method=&quot;nearest&quot;).item()&#10;                        if not np.isnan(cap_height) and cap_height &lt;= max_height:&#10;                            idx = np.argmin(np.abs(height[valid] - cap_height))&#10;                            key = f&quot;hatpro_cap_{ts_str}&quot;&#10;                            obs_data[key] = (temp[valid][idx], cap_height)&#10;&#10;                ds_hatpro.close()&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Error in loading HATPRO: {e}&quot;)&#10;&#10;    print(f&quot;  Creating frames...&quot;)&#10;&#10;    max_q = 30  # Maximum humidity for scale&#10;&#10;    # Create figure with subplots: [Temp/Humidity] | [Wind Speed/Direction]&#10;    fig = make_subplots(rows=1, cols=2, specs=[[{&quot;secondary_y&quot;: False}, {&quot;secondary_y&quot;: False}]],&#10;                        horizontal_spacing=0.12, column_widths=[0.6, 0.4])&#10;&#10;    # Create frames for slider - one frame per timestep&#10;    frames = []&#10;    for ts_str in timestamps:&#10;        frame_traces = []&#10;&#10;        # ====== SUBPLOT 1: Temperature &amp; Humidity ======&#10;        # Add model traces (temperature)&#10;        for model in MODEL_ORDER:&#10;            if ts_str in model_data.get(model, {}):&#10;                temp, height = model_data[model][ts_str]&#10;                line_dash = icon_2te_hatpro_linestyle if model == &quot;ICON2TE&quot; else &quot;solid&quot;&#10;                frame_traces.append(go.Scatter(x=temp, y=height, mode='lines', name=model,&#10;                                               line=dict(color=model_colors_temp_wind[model], dash=line_dash,&#10;                                                         width=1.5), legendgroup=model,&#10;                                               showlegend=True, xaxis='x1', yaxis='y1'))&#10;&#10;                # Add CAP marker&#10;                if ts_str in cap_data.get(model, {}):&#10;                    temp_cap, height_cap = cap_data[model][ts_str]&#10;                    frame_traces.append(go.Scatter(x=[temp_cap], y=[height_cap], mode='markers',&#10;                                                   marker=dict(symbol='x', size=8, color=model_colors_temp_wind[model],&#10;                                                               line=dict(width=0.5,&#10;                                                                         color=model_colors_temp_wind[model])),&#10;                                                   name=f&quot;{model} CAP&quot;,&#10;                                                   legendgroup=model, showlegend=False,&#10;                                                   hovertemplate=f&quot;{model} CAP: {height_cap:.0f}m&lt;extra&gt;&lt;/extra&gt;&quot;,&#10;                                                   xaxis='x1', yaxis='y1'))&#10;&#10;            # Add specific humidity traces (on secondary x-axis x3 = top of subplot 1)&#10;            if ts_str in model_humidity_data.get(model, {}):&#10;                q, height = model_humidity_data[model][ts_str]&#10;                line_dash = icon_2te_hatpro_linestyle if model == &quot;ICON2TE&quot; else &quot;solid&quot;&#10;&#10;                frame_traces.append(go.Scatter(x=q, y=height, mode='lines', name=f&quot;{model} q&quot;,&#10;                                               line=dict(color=model_colors_humidity[model], dash=line_dash, width=1.0),&#10;                                               legendgroup=model,&#10;                                               showlegend=False, xaxis='x3', yaxis='y1'))&#10;&#10;        # Add observations (only for Innsbruck points; names in confg always start with &quot;ibk&quot;) - subplot 1&#10;        if point_name.startswith(&quot;ibk&quot;):&#10;            # Add Radiosonde: all variables but only 1 measurement at 02:15 UTC&#10;            if &quot;radiosonde&quot; in obs_data:&#10;                temp, height = obs_data[&quot;radiosonde&quot;]&#10;                frame_traces.append(go.Scatter(x=temp, y=height, mode='lines', name=&quot;Radiosonde (from 02:18 UTC)&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;Radiosonde&quot;], width=1.5),&#10;                                               legendgroup=&quot;Radiosonde&quot;,&#10;                                               showlegend=True, xaxis='x1', yaxis='y1'))&#10;&#10;                if &quot;radiosonde_cap&quot; in obs_data:&#10;                    temp_cap, height_cap = obs_data[&quot;radiosonde_cap&quot;]&#10;                    frame_traces.append(go.Scatter(x=[temp_cap], y=[height_cap], mode='markers',&#10;                                                   marker=dict(symbol='x', size=8,&#10;                                                               color=model_colors_temp_wind[&quot;Radiosonde&quot;],&#10;                                                               line=dict(width=0.5,&#10;                                                                         color=model_colors_temp_wind[&quot;Radiosonde&quot;])),&#10;                                                   name=&quot;Radiosonde CAP&quot;, legendgroup=&quot;Radiosonde&quot;, showlegend=False,&#10;                                                   hovertemplate=f&quot;Radiosonde CAP: {height_cap:.0f}m&lt;extra&gt;&lt;/extra&gt;&quot;,&#10;                                                   xaxis='x1', yaxis='y1'))&#10;            # Add Radiosonde humidity&#10;            if &quot;radiosonde_humidity&quot; in obs_data:&#10;                q, height = obs_data[&quot;radiosonde_humidity&quot;]&#10;                frame_traces.append(&#10;                    go.Scatter(x=q, y=height, mode='lines', name=&quot;Radiosonde q&quot;,&#10;                               line=dict(color=model_colors_humidity[&quot;Radiosonde&quot;], width=1.0),&#10;                               legendgroup=&quot;Radiosonde&quot;, showlegend=False, xaxis='x3', yaxis='y1'))&#10;&#10;            # HATPRO (time-dependent)&#10;            if &quot;hatpro&quot; in obs_data and ts_str in obs_data[&quot;hatpro&quot;]:&#10;                temp, height = obs_data[&quot;hatpro&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=temp, y=height, mode='lines', name=&quot;HATPRO&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;HATPRO&quot;], width=2.0, dash=&quot;dot&quot;),&#10;                                               legendgroup=&quot;HATPRO&quot;,&#10;                                               showlegend=True, xaxis='x1', yaxis='y1'))&#10;&#10;                cap_key = f&quot;hatpro_cap_{ts_str}&quot;&#10;                if cap_key in obs_data:&#10;                    temp_cap, height_cap = obs_data[cap_key]&#10;                    frame_traces.append(go.Scatter(x=[temp_cap], y=[height_cap], mode='markers',&#10;                                                   marker=dict(symbol='x', size=8,&#10;                                                               color=model_colors_temp_wind[&quot;HATPRO&quot;],&#10;                                                               line=dict(width=0.8,&#10;                                                                         color=model_colors_temp_wind[&quot;HATPRO&quot;])),&#10;                                                   name=&quot;HATPRO CAP&quot;,&#10;                                                   legendgroup=&quot;HATPRO&quot;, showlegend=False,&#10;                                                   hovertemplate=f&quot;HATPRO CAP: {height_cap:.0f}m&lt;extra&gt;&lt;/extra&gt;&quot;,&#10;                                                   xaxis='x1', yaxis='y1'))&#10;&#10;            # HATPRO humidity (time-dependent)&#10;            if &quot;hatpro_humidity&quot; in obs_data and ts_str in obs_data[&quot;hatpro_humidity&quot;]:&#10;                q, height = obs_data[&quot;hatpro_humidity&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=q, y=height, mode='lines', name=&quot;HATPRO q&quot;,&#10;                                               line=dict(color=model_colors_humidity[&quot;HATPRO&quot;], width=1, dash=&quot;dot&quot;),&#10;                                               legendgroup=&quot;HATPRO&quot;,&#10;                                               showlegend=False, xaxis='x3', yaxis='y1'))&#10;&#10;        # ====== SUBPLOT 2: Wind Speed &amp; Direction ======&#10;        # Add wind speed traces (bottom x-axis of subplot 2) - row=1, col=2&#10;        for model in MODEL_ORDER:&#10;            if ts_str in model_wspd_data.get(model, {}):&#10;                wspd, height = model_wspd_data[model][ts_str]&#10;                line_dash = icon_2te_hatpro_linestyle if model == &quot;ICON2TE&quot; else &quot;solid&quot;&#10;&#10;                frame_traces.append(go.Scatter(x=wspd, y=height, mode='lines', name=f&quot;{model} wspd&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[model], dash=line_dash,&#10;                                                         width=1.5), legendgroup=model,&#10;                                               showlegend=False, xaxis='x2', yaxis='y2'))&#10;&#10;            # Add wind direction traces (top x-axis x4 of subplot 2)&#10;            if ts_str in model_udir_data.get(model, {}):&#10;                wdir, height = model_udir_data[model][ts_str]&#10;&#10;                # Use open circles for ICON2TE to match its dashed line style&#10;                marker_symbol = 'circle-open' if model == &quot;ICON2TE&quot; else 'circle'&#10;&#10;                frame_traces.append(go.Scatter(x=wdir, y=height, mode='markers', name=f&quot;{model} wdir&quot;,&#10;                                               marker=dict(color=model_colors_temp_wind[model], size=5,&#10;                                                           symbol=marker_symbol), legendgroup=model,&#10;                                               showlegend=False, xaxis='x4', yaxis='y2'))&#10;&#10;        # Add observation wind data (only for Innsbruck points) - subplot 2&#10;        if point_name.startswith(&quot;ibk&quot;):&#10;            # Radiosonde wind speed (constant)&#10;            if &quot;radiosonde_wspd&quot; in obs_data:&#10;                wspd, height = obs_data[&quot;radiosonde_wspd&quot;]&#10;                frame_traces.append(go.Scatter(x=wspd, y=height, mode='lines', name=&quot;Radiosonde wspd&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;Radiosonde&quot;], width=1.5),&#10;                                               legendgroup=&quot;Radiosonde&quot;, showlegend=False, xaxis='x2', yaxis='y2'))&#10;&#10;            # Radiosonde wind direction (constant)&#10;            if &quot;radiosonde_udir&quot; in obs_data:&#10;                wdir, height = obs_data[&quot;radiosonde_udir&quot;]&#10;                frame_traces.append(go.Scatter(x=wdir, y=height, mode='markers', name=&quot;Radiosonde wdir&quot;,&#10;                                               marker=dict(color=model_colors_temp_wind[&quot;Radiosonde&quot;], size=5,&#10;                                                           symbol='circle'),&#10;                                               legendgroup=&quot;Radiosonde&quot;, showlegend=False, xaxis='x4', yaxis='y2'))&#10;&#10;            # SL88 LIDAR wind speed (time-dependent)&#10;            if &quot;lidar_wspd&quot; in obs_data and ts_str in obs_data[&quot;lidar_wspd&quot;]:&#10;                wspd, height = obs_data[&quot;lidar_wspd&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=wspd, y=height, mode='lines', name=&quot;SL88 LIDAR&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;HATPRO&quot;], width=2.0, dash=&quot;dot&quot;),&#10;                                               legendgroup=&quot;SL88_LIDAR&quot;,&#10;                                               showlegend=True, xaxis='x2', yaxis='y2'))&#10;&#10;            # SL88 LIDAR wind direction (time-dependent)&#10;            if &quot;lidar_udir&quot; in obs_data and ts_str in obs_data[&quot;lidar_udir&quot;]:&#10;                wdir, height = obs_data[&quot;lidar_udir&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=wdir, y=height, mode='markers', name=&quot;SL88 LIDAR wdir&quot;,&#10;                                               marker=dict(color=model_colors_temp_wind[&quot;HATPRO&quot;], size=5,&#10;                                                           symbol='circle'),&#10;                                               legendgroup=&quot;SL88_LIDAR&quot;, showlegend=False, xaxis='x4', yaxis='y2'))&#10;&#10;        # Format current timestamp for this frame&#10;        formatted_ts = pd.to_datetime(ts_str).strftime('%dth %H:%M')&#10;        frames.append(go.Frame(data=frame_traces, name=ts_str,&#10;                               layout=go.Layout(&#10;                                   title_text=f&quot;Vertical profiles at {point['name']}, {point['height']} m - {formatted_ts} UTC&quot;)))&#10;&#10;    # Add initial data (first timestep)&#10;    for trace in frames[0].data:&#10;        fig.add_trace(trace, row=1, col=1 if trace.xaxis in ['x1', 'x3'] else 2)&#10;&#10;    # Assign frames&#10;    fig.frames = frames&#10;&#10;    # Create slider&#10;    sliders = [dict(active=0, yanchor=&quot;top&quot;, y=-0.12, xanchor=&quot;left&quot;, x=0.1,&#10;                    currentvalue=dict(prefix=&quot;Time: &quot;, visible=True, xanchor=&quot;center&quot;, font=dict(size=14)),&#10;                    pad=dict(b=10, t=50),&#10;                    len=0.8, transition=dict(duration=0), steps=[dict(&#10;            args=[[ts_str], dict(frame=dict(duration=0, redraw=True), mode=&quot;immediate&quot;, transition=dict(duration=0))],&#10;            label=&quot;&quot;,  # Empty label&#10;            method=&quot;animate&quot;) for ts_str in timestamps])]&#10;&#10;    # Update layout&#10;    formatted_ts_initial = pd.to_datetime(timestamps[0]).strftime('%dth %H:%M')&#10;    fig.update_layout(title_text=f&quot;Vertical profiles at {point['name']}, {point['height']} m - {formatted_ts_initial}&quot;,&#10;                      height=700, width=1400, hovermode='closest', template='plotly_white', sliders=sliders,&#10;                      legend=dict(orientation=&quot;h&quot;, yanchor=&quot;top&quot;, y=-0.14, xanchor=&quot;center&quot;, x=0.5,&#10;                                  bgcolor=&quot;rgba(255, 255, 255, 0.8)&quot;, bordercolor=&quot;lightgray&quot;, borderwidth=1),&#10;                      updatemenus=[&#10;                          dict(type=&quot;buttons&quot;, direction=&quot;left&quot;, x=0.0, y=-0.12, xanchor=&quot;left&quot;, yanchor=&quot;top&quot;,&#10;                               pad=dict(t=10, b=10),&#10;                               buttons=[dict(label=&quot;▶ Play&quot;, method=&quot;animate&quot;,&#10;                                             args=[None, dict(frame=dict(duration=800, redraw=True),&#10;                                                              fromcurrent=True, mode=&quot;immediate&quot;,&#10;                                                              transition=dict(duration=0))]),&#10;                                        dict(label=&quot;⏸ Pause&quot;, method=&quot;animate&quot;,&#10;                                             args=[[None], dict(frame=dict(duration=0, redraw=False),&#10;                                                                mode=&quot;immediate&quot;,&#10;                                                                transition=dict(duration=0))])])])&#10;&#10;    # Update x-axes and y-axes&#10;    # Subplot 1 (Temperature &amp; Humidity)&#10;    fig.update_xaxes(title_text=&quot;Temperature [°C]&quot;, range=[8, 20], row=1, col=1)&#10;    fig.update_yaxes(title_text=&quot;Height above terrain [m]&quot;, range=[0, plot_max_height], row=1, col=1)&#10;&#10;    # Subplot 2 (Wind) - no y-axis labels (redundant with left plot), but synchronized zoom&#10;    fig.update_xaxes(title_text=&quot;Wind Speed [m/s]&quot;, range=[0, 10], row=1, col=2)&#10;    fig.update_yaxes(title_text=&quot;&quot;, range=[0, plot_max_height], showticklabels=False, matches='y', row=1, col=2)&#10;&#10;    # Add secondary x-axis for humidity (top of subplot 1) - x3&#10;    fig.update_layout(&#10;        xaxis3=dict(title=&quot;Specific Humidity [g/kg]&quot;, overlaying='x', side='top', range=[0, max_q], anchor='y',&#10;                    showgrid=False))&#10;&#10;    # Add secondary x-axis for wind direction (top of subplot 2) - x4&#10;    fig.update_layout(xaxis4=dict(title=&quot;Wind Direction [°]&quot;, overlaying='x2', side='top', range=[0, 360], anchor='y2',&#10;                                  showgrid=False))&#10;    return fig&#10;&#10;&#10;def plot_save_all_points_with_slider(start_time: str = &quot;2017-10-16T00:00:00&quot;, end_time: str = &quot;2017-10-16T12:00:00&quot;,&#10;                                     time_step_hours: float = 1.0, max_height: float = 5000,&#10;                                     plot_max_height: float = 2000, point_names: List[str] = confg.ALL_POINTS) -&gt; None:&#10;    &quot;&quot;&quot;&#10;    Create and save individual slider plots for each point location.&#10;    &#10;    Creates one HTML file per point, each with its own time slider.&#10;    This is more reliable than trying to animate small multiples.&#10;    &#10;    Args:&#10;        start_time: Start timestamp ISO format (e.g. &quot;2017-10-16T00:00:00&quot;)&#10;        end_time: End timestamp ISO format (e.g. &quot;2017-10-16T12:00:00&quot;)&#10;        time_step_hours: Time step in hours between frames (default: 1.0)&#10;        max_height: Maximum height in meters to load data (default: 5000m)&#10;        plot_max_height: Maximum height in meters to display initially (default: 2000m)&#10;        point_names: List of points to plot (default: confg.ALL_POINTS)&#10;    &quot;&quot;&quot;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;Creating individual slider plots for {len(point_names)} points&quot;)&#10;    print(f&quot;Time range: {start_time} to {end_time}, step: {time_step_hours}h&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;    # Generate list of timestamps&#10;    timestamps = pd.date_range(start=start_time, end=end_time, freq=f&quot;{int(time_step_hours * 60)}min&quot;).strftime(&#10;        &quot;%Y-%m-%dT%H:%M:%S&quot;).tolist()&#10;&#10;    print(f&quot;Total timesteps: {len(timestamps)}\n&quot;)&#10;    # Ensure output directory exists&#10;    html_dir = os.path.join(confg.dir_PLOTS, &quot;vertical_plots&quot;)&#10;    os.makedirs(html_dir, exist_ok=True)&#10;&#10;    # Create plot for each point&#10;    for point_name in point_names:&#10;        try:&#10;            point = confg.ALL_POINTS.get(point_name)&#10;            if point is None:&#10;                print(f&quot;⚠ Skipping {point_name} - not found in confg&quot;)&#10;                continue&#10;&#10;            print(f&quot;\n{'-' * 70}&quot;)&#10;            print(f&quot;Processing: {point['name']} ({point_name})&quot;)&#10;            print(f&quot;{'-' * 70}&quot;)&#10;&#10;            # Create the plot with slider&#10;            fig = plot_single_point_with_slider(point_name, timestamps=timestamps, max_height=max_height,&#10;                                                plot_max_height=plot_max_height)&#10;            # Save to HTML&#10;            html_path = os.path.join(html_dir, f&quot;vertical_profile_{point_name}_slider.html&quot;)&#10;            fig.write_html(html_path)&#10;            print(f&quot;✓ Saved: {html_path}&quot;)&#10;&#10;        except Exception as e:&#10;            print(f&quot;✗ Error processing {point_name}: {e}&quot;)&#10;            continue&#10;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;✓ All plots created successfully!&quot;)&#10;    print(f&quot;  Location: {html_dir}&quot;)&#10;    print(f&quot;  - Use the slider to move through timesteps&quot;)&#10;    print(f&quot;  - Click 'Play' to animate&quot;)&#10;    print(f&quot;  - Data loaded up to {max_height}m, displayed up to {plot_max_height}m&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Create vertical temperature profile plot for 04:00 UTC on October 16, 2017&#10;    # Data is loaded up to 5000m but initially displayed up to 2000m&#10;    # Users can zoom out in the interactive HTML to see higher altitudes&#10;    # plot_save_vertical_profiles(timestamp=&quot;2017-10-16T04:00:00&quot;, max_height=5000, plot_max_height=2000)&#10;&#10;    # Create interactive plot with time slider&#10;    # Shows profiles from midnight to noon on October 16, 2017&#10;    plot_save_all_points_with_slider(start_time=&quot;2017-10-15T14:00:00&quot;, end_time=&quot;2017-10-16T12:00:00&quot;,&#10;                                     time_step_hours=0.5, max_height=3000, plot_max_height=800, # )&#10;                                     point_names=[&quot;ibk_uni&quot;, &quot;telfs&quot;])&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Plot vertical temperature profiles for all models at fixed points.&#10;&#10;This module creates interactive plots showing temperature profiles with height for different&#10;weather models (AROME, ICON, ICON2TE, UM, WRF) and observations (Radiosonde, HATPRO)&#10;at various locations. The plots include CAP (Cold Air Pool) height markers when available.&#10;&#10;Main functionality:&#10;- Load timeseries data from saved files (or read fresh data if not available)&#10;- Add radiosonde and HATPRO observations for Innsbruck points&#10;- Create small multiples plots showing all points side-by-side&#10;- Save interactive HTML plots&#10;&quot;&quot;&quot;&#10;from __future__ import annotations&#10;&#10;# Fix for OpenMP duplicate library error on Windows&#10;import os&#10;os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'&#10;&#10;import os&#10;from typing import List&#10;&#10;import numpy as np&#10;import pandas as pd&#10;import plotly.graph_objects as go&#10;import xarray as xr&#10;&#10;from plotly.subplots import make_subplots&#10;&#10;import confg&#10;from confg import model_colors_temp_wind, model_colors_humidity, icon_2te_hatpro_linestyle&#10;from read_in_hatpro_radiosonde import read_radiosonde_dataset&#10;from calculations_and_plots.calc_cap_height import cap_height_profile&#10;# Import timeseries management functions&#10;from calculations_and_plots.manage_timeseries import (load_or_read_timeseries, MODEL_ORDER)&#10;&#10;&#10;&#10;&#10;# Observation data paths; is actually in confg!&#10;# RADIOSONDE_PATH = r&quot;D:\MSc_Arbeit\data\radiosonde_ibk_smoothed.nc&quot;&#10;# HATPRO_PATH = r&quot;D:\MSc_Arbeit\data\Observations\HATPRO_obs\hatpro_interpolated_arome_height_as_z.nc&quot;&#10;&#10;&#10;def get_obs_cap_path(obs_type: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Get the path to the computed CAP height file for observations.&#10;    &#10;    Args:&#10;        obs_type: Either &quot;radiosonde&quot; or &quot;hatpro&quot;&#10;    &#10;    Returns:&#10;        Full path to the CAP height NetCDF file&#10;    &quot;&quot;&quot;&#10;    import confg&#10;    cap_dir = os.path.join(confg.data_folder, &quot;calculated_cap_height&quot;)&#10;    return os.path.join(cap_dir, f&quot;{obs_type}_cap_height.nc&quot;)&#10;&#10;&#10;def _get_cap_height_value(cap_height_da: xr.DataArray, point: dict, ts: np.datetime64) -&gt; float:&#10;    &quot;&quot;&quot;&#10;    Extract CAP height value from DataArray, handling different dimension structures.&#10;    Returns NaN if extraction fails.&#10;    &quot;&quot;&quot;&#10;    if not cap_height_da.dims:&#10;        # Scalar value&#10;        return cap_height_da.item()&#10;&#10;    if &quot;lat&quot; in cap_height_da.dims and &quot;lon&quot; in cap_height_da.dims:&#10;        # Spatial + time dimensions&#10;        return cap_height_da.sel(lat=point[&quot;lat&quot;], lon=point[&quot;lon&quot;], time=ts).item()&#10;&#10;    # Only time dimension&#10;    return cap_height_da.sel(time=ts, method=&quot;nearest&quot;).item()&#10;&#10;&#10;def _load_or_compute_cap_heights(model: str, ds_filtered: xr.Dataset, point: dict, timestamps: List[str],&#10;                                 ts_array: List[np.datetime64], model_data: dict, max_height: float) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Compute CAP heights from timeseries (point) data.&#10;    Returns dict mapping timestamp strings to (temp_at_cap, cap_height) tuples (tuple is needed so that the&#10;    cap-marker is at the right temperature in the plot afterwards).&#10;    &quot;&quot;&quot;&#10;    cap_data = {}&#10;&#10;    ds_with_cap = cap_height_profile(ds_filtered, consecutive=3, model=model)&#10;    cap_height_da = ds_with_cap[&quot;cap_height&quot;]&#10;&#10;    # Extract CAP heights for each timestamp&#10;    for ts_str, ts in zip(timestamps, ts_array):&#10;        cap_height = _get_cap_height_value(cap_height_da, point, ts)&#10;&#10;        if np.isnan(cap_height) or cap_height &gt; max_height:&#10;            continue&#10;&#10;        if ts_str not in model_data[model]:&#10;            continue&#10;&#10;        temp_data, height_data = model_data[model][ts_str]&#10;        if len(height_data) == 0:&#10;            continue&#10;&#10;        idx = np.argmin(np.abs(height_data - cap_height))&#10;        temp_at_cap = temp_data[idx]&#10;        cap_data[ts_str] = (temp_at_cap, cap_height)&#10;&#10;    return cap_data&#10;&#10;&#10;def plot_single_point_with_slider(point_name: str, timestamps: List[str], max_height: float = 5000,&#10;                                  plot_max_height: float = 2000,&#10;                                  variables: list = [&quot;udir&quot;, &quot;wspd&quot;, &quot;q&quot;, &quot;p&quot;, &quot;th&quot;, &quot;temp&quot;, &quot;z&quot;,&#10;                                                     &quot;z_unstag&quot;]) -&gt; go.Figure:&#10;    &quot;&quot;&quot;&#10;    Create an interactive plot with time slider for a single point location.&#10;    &#10;    Users can slide through different timesteps and see the temperature profiles update dynamically.&#10;    The plot shows all models and observations at one location.&#10;    &#10;    Args:&#10;        point_name: Point location name from confg.py (e.g. &quot;ibk_villa&quot;)&#10;        timestamps: List of ISO format timestamp strings&#10;        max_height: Maximum height in meters to load data (default: 5000m)&#10;        plot_max_height: Maximum height in meters to display on y-axis (default: 2000m)&#10;    &#10;    Returns:&#10;        Plotly figure object with the interactive time slider&#10;    &quot;&quot;&quot;&#10;    point = confg.ALL_POINTS.get(point_name)&#10;    if point is None:&#10;        raise ValueError(f&quot;Point {point_name} not found in confg&quot;)&#10;&#10;    print(f&quot;Creating slider plot for {point['name']} with {len(timestamps)} timesteps...&quot;)&#10;&#10;    # Convert timestamp strings to numpy datetime64&#10;    ts_array = [np.datetime64(ts) for ts in timestamps]&#10;&#10;    # Pre-load all data for all timesteps&#10;    print(f&quot;  Loading data for all models and timesteps...&quot;)&#10;    model_data = {}  # {model: {timestamp: (temp, height)}}&#10;    model_humidity_data = {}  # {model: {timestamp: (q, height)}}&#10;    model_wspd_data = {}  # {model: {timestamp: (wspd, height)}}&#10;    model_udir_data = {}  # {model: {timestamp: (wdir, height)}}&#10;    obs_data = {}  # {obs_type: data}&#10;    cap_data = {}  # {model: {timestamp: (temp_at_cap, cap_height)}}&#10;&#10;    # Load model data&#10;    for model in MODEL_ORDER:&#10;        model_data[model] = {}&#10;        model_humidity_data[model] = {}&#10;        model_wspd_data[model] = {}&#10;        model_udir_data[model] = {}&#10;&#10;        # Load timeseries dataset, for model data&#10;        ds = load_or_read_timeseries(model=model, point=point, point_name=point_name, variables_list=variables,&#10;                                     height_as_z_coord=&quot;above_terrain&quot;)&#10;        if ds is None:&#10;            print(f&quot;    Warning: Could not load {model} data&quot;)&#10;            continue&#10;&#10;        # Get height variable&#10;        if &quot;height&quot; not in ds.coords:&#10;            print(f&quot;    Warning: No height coordinate found for {model}&quot;)&#10;            ds.close()&#10;            continue&#10;&#10;        height_var = ds.coords[&quot;height&quot;]&#10;        ds_filtered = ds.where(height_var &lt;= max_height, drop=True)&#10;&#10;        # Extract temperature and height values for each timestamp&#10;        for ts_str, ts in zip(timestamps, ts_array):&#10;            temp = ds_filtered[&quot;temp&quot;].sel(time=ts).values&#10;            height = ds_filtered.coords[&quot;height&quot;].values&#10;&#10;            # Filter NaNs for temperature&#10;            valid = ~np.isnan(temp) &amp; ~np.isnan(height)&#10;            model_data[model][ts_str] = (temp[valid], height[valid])&#10;&#10;            # Extract humidity data (q) if available&#10;            if &quot;q&quot; in ds_filtered:&#10;                q = ds_filtered[&quot;q&quot;].sel(time=ts).values&#10;                # Convert from kg/kg to g/kg&#10;                q = q * 1000&#10;                # Filter NaNs for humidity&#10;                valid_q = ~np.isnan(q) &amp; ~np.isnan(height)&#10;                model_humidity_data[model][ts_str] = (q[valid_q], height[valid_q])&#10;&#10;            # Extract wind speed data (wspd) if available&#10;            if &quot;wspd&quot; in ds_filtered:&#10;                wspd = ds_filtered[&quot;wspd&quot;].sel(time=ts).values&#10;                valid_wspd = ~np.isnan(wspd) &amp; ~np.isnan(height)&#10;                model_wspd_data[model][ts_str] = (wspd[valid_wspd], height[valid_wspd])&#10;&#10;            # Extract wind direction data (udir) if available&#10;            if &quot;udir&quot; in ds_filtered:&#10;                udir = ds_filtered[&quot;udir&quot;].sel(time=ts).values&#10;                valid_udir = ~np.isnan(udir) &amp; ~np.isnan(height)&#10;                model_udir_data[model][ts_str] = (udir[valid_udir], height[valid_udir])&#10;&#10;        # Load or compute CAP heights&#10;        try:&#10;            cap_data[model] = _load_or_compute_cap_heights(model, ds_filtered, point, timestamps, ts_array, model_data,&#10;                                                           max_height)&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Could not load/compute CAP height for {model}: {e}&quot;)&#10;&#10;        ds.close()&#10;&#10;    # Load observation data (only for Innsbruck points)&#10;    if point_name.startswith(&quot;ibk&quot;):&#10;        # Radiosonde (no time dimension)&#10;        try:&#10;            ds_radiosonde = read_radiosonde_dataset(height_as_z_coord=&quot;above_terrain&quot;)&#10;            ds_filtered = ds_radiosonde.where(ds_radiosonde[&quot;height&quot;] &lt;= max_height, drop=True)&#10;            temp = ds_filtered[&quot;temp&quot;].values&#10;            height = ds_filtered[&quot;height&quot;].values&#10;            valid = ~np.isnan(temp) &amp; ~np.isnan(height)&#10;            obs_data[&quot;radiosonde&quot;] = (temp[valid], height[valid])&#10;&#10;            # Extract humidity data (q) if available&#10;            if &quot;q&quot; in ds_filtered:&#10;                q = ds_filtered[&quot;q&quot;].values  # in kg/kg&#10;                # Convert from kg/kg to g/kg&#10;                q = q * 1000&#10;                valid_q = ~np.isnan(q) &amp; ~np.isnan(height)  # filter NaNs ...&#10;                obs_data[&quot;radiosonde_humidity&quot;] = (q[valid_q], height[valid_q])&#10;&#10;            # Extract wind speed data (wspd) if available&#10;            if &quot;wspd&quot; in ds_filtered:&#10;                wspd = ds_filtered[&quot;wspd&quot;].values&#10;                valid_wspd = ~np.isnan(wspd) &amp; ~np.isnan(height)&#10;                obs_data[&quot;radiosonde_wspd&quot;] = (wspd[valid_wspd], height[valid_wspd])&#10;&#10;            # Extract wind direction data (udir) if available&#10;            if &quot;udir&quot; in ds_filtered:&#10;                udir = ds_filtered[&quot;udir&quot;].values&#10;                valid_udir = ~np.isnan(udir) &amp; ~np.isnan(height)&#10;                obs_data[&quot;radiosonde_udir&quot;] = (udir[valid_udir], height[valid_udir])&#10;&#10;            # Radiosonde CAP height was searched in plot and defined in confg&#10;            if not np.isnan(confg.radiosonde_cap_height) and confg.radiosonde_cap_height &lt;= max_height:&#10;                idx = np.argmin(np.abs(height[valid] - confg.radiosonde_cap_height))&#10;                obs_data[&quot;radiosonde_cap&quot;] = (temp[valid][idx], confg.radiosonde_cap_height)&#10;&#10;            ds_radiosonde.close()&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Error in loading Radiosonde: {e}&quot;)&#10;&#10;        # SL88 LIDAR (time-dependent wind data)&#10;        try:&#10;            if os.path.exists(confg.lidar_sl88_merged_path):&#10;                print(f&quot;    Loading SL88 LIDAR data&quot;)&#10;                ds_lidar = xr.open_dataset(confg.lidar_sl88_merged_path)&#10;&#10;                obs_data[&quot;lidar_wspd&quot;] = {}&#10;                obs_data[&quot;lidar_udir&quot;] = {}&#10;&#10;                for ts_str, ts in zip(timestamps, ts_array):&#10;                    # Select nearest time&#10;                    ds_ts = ds_lidar.sel(time=ts, method='nearest', tolerance='3min')&#10;&#10;                    # Get height values in meters (from height_m coordinate)&#10;                    if 'height_m' in ds_ts.coords:&#10;                        height = ds_ts['height_m'].values&#10;                    else:&#10;                        print(f&quot;    Warning: No height_m coordinate in SL88 LIDAR data&quot;)&#10;                        continue&#10;&#10;                    # Filter to max_height&#10;                    height_mask = height &lt;= max_height&#10;                    height_filtered = height[height_mask]&#10;&#10;                    # Extract wind speed (ff variable)&#10;                    if 'ff' in ds_ts:&#10;                        wspd = ds_ts['ff'].values&#10;                        wspd_filtered = wspd[height_mask]&#10;                        valid_wspd = ~np.isnan(wspd_filtered) &amp; ~np.isnan(height_filtered)&#10;                        obs_data[&quot;lidar_wspd&quot;][ts_str] = (wspd_filtered[valid_wspd], height_filtered[valid_wspd])&#10;&#10;                    # Extract wind direction (dd variable)&#10;                    if 'dd' in ds_ts:&#10;                        wdir = ds_ts['dd'].values&#10;                        wdir_filtered = wdir[height_mask]&#10;                        valid_wdir = ~np.isnan(wdir_filtered) &amp; ~np.isnan(height_filtered)&#10;                        obs_data[&quot;lidar_udir&quot;][ts_str] = (wdir_filtered[valid_wdir], height_filtered[valid_wdir])&#10;&#10;                ds_lidar.close()&#10;                print(f&quot;    ✓ SL88 LIDAR data loaded successfully&quot;)&#10;            else:&#10;                print(f&quot;    Warning: SL88 LIDAR merged file not found at {confg.lidar_sl88_merged_path}&quot;)&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Error in loading SL88 LIDAR: {e}&quot;)&#10;&#10;        # HATPRO (time-dependent)&#10;        try:&#10;            # Check for HATPRO file with CAP height first&#10;            if os.path.exists(confg.hatpro_with_cap_height):&#10;                # Load HATPRO data with pre-computed CAP height&#10;                print(f&quot;    Loading HATPRO data with CAP height&quot;)&#10;                ds_hatpro = xr.open_dataset(confg.hatpro_with_cap_height)&#10;                hatpro_cap_da = ds_hatpro[&quot;cap_height&quot;]&#10;&#10;            elif os.path.exists(confg.hatpro_calced_vars):  # used interpolated heights to arome levels -&gt; change to&#10;                # smooth HATPRO!&#10;                # Load original HATPRO data and compute CAP height&#10;                print(f&quot;    Loading HATPRO data&quot;)&#10;                ds_hatpro = xr.open_dataset(confg.hatpro_calced_vars)&#10;&#10;                print(f&quot;    Computing CAP height for HATPRO...&quot;)&#10;                # Filter to max_height before computing CAP&#10;                ds_hatpro_filtered = ds_hatpro.where(ds_hatpro[&quot;height&quot;] &lt;= max_height, drop=True)&#10;                ds_hatpro_with_cap = cap_height_profile(ds_hatpro_filtered, consecutive=3, model=&quot;HATPRO&quot;)&#10;&#10;                # Add CAP height to original (non-filtered) dataset&#10;                ds_hatpro[&quot;cap_height&quot;] = ds_hatpro_with_cap[&quot;cap_height&quot;]&#10;                hatpro_cap_da = ds_hatpro[&quot;cap_height&quot;]&#10;&#10;                # Save complete dataset with CAP height&#10;                print(f&quot;    Saving HATPRO dataset with CAP height to {confg.hatpro_with_cap_height}&quot;)&#10;                ds_hatpro.to_netcdf(confg.hatpro_with_cap_height)&#10;                print(f&quot;    ✓ Saved successfully&quot;)&#10;            else:&#10;                print(f&quot;    Warning: HATPRO file not found&quot;)&#10;                ds_hatpro = None&#10;                hatpro_cap_da = None&#10;&#10;            if ds_hatpro is not None:&#10;                obs_data[&quot;hatpro&quot;] = {}&#10;                obs_data[&quot;hatpro_humidity&quot;] = {}&#10;                obs_data[&quot;hatpro_wspd&quot;] = {}&#10;                obs_data[&quot;hatpro_udir&quot;] = {}&#10;&#10;                for ts_str, ts in zip(timestamps, ts_array):&#10;                    ds_ts = ds_hatpro.sel(time=ts)&#10;                    ds_filtered = ds_ts.where(ds_ts[&quot;height&quot;] &lt;= max_height, drop=True)&#10;&#10;                    temp = ds_filtered[&quot;temp&quot;].values&#10;                    height = ds_filtered[&quot;height&quot;].values&#10;                    valid = ~np.isnan(temp) &amp; ~np.isnan(height)&#10;                    obs_data[&quot;hatpro&quot;][ts_str] = (temp[valid], height[valid])&#10;                    # creates large dict w. radiosonde w. cap_height &amp; hatpro data for that timestamp&#10;&#10;                    # Extract humidity data (q) if available; wind data isn't available -&gt; maybe include LIDAR?&#10;                    if &quot;q&quot; in ds_filtered:&#10;                        q = ds_filtered[&quot;q&quot;].values  # in kg/kg&#10;                        # Convert from kg/kg to g/kg&#10;                        q = q * 1000&#10;                        valid_q = ~np.isnan(q) &amp; ~np.isnan(height)  # filter NaNs ...&#10;                        obs_data[&quot;hatpro_humidity&quot;][ts_str] = (q[valid_q], height[valid_q])&#10;&#10;                    # CAP height&#10;                    if hatpro_cap_da is not None:&#10;                        cap_height = hatpro_cap_da.sel(time=ts, method=&quot;nearest&quot;).item()&#10;                        if not np.isnan(cap_height) and cap_height &lt;= max_height:&#10;                            idx = np.argmin(np.abs(height[valid] - cap_height))&#10;                            key = f&quot;hatpro_cap_{ts_str}&quot;&#10;                            obs_data[key] = (temp[valid][idx], cap_height)&#10;&#10;                ds_hatpro.close()&#10;        except Exception as e:&#10;            print(f&quot;    Warning: Error in loading HATPRO: {e}&quot;)&#10;&#10;    print(f&quot;  Creating frames...&quot;)&#10;&#10;    max_q = 30  # Maximum humidity for scale&#10;&#10;    # Create figure with subplots: [Temp/Humidity] | [Wind Speed/Direction]&#10;    fig = make_subplots(rows=1, cols=2, specs=[[{&quot;secondary_y&quot;: False}, {&quot;secondary_y&quot;: False}]],&#10;                        horizontal_spacing=0.12, column_widths=[0.6, 0.4])&#10;&#10;    # Create frames for slider - one frame per timestep&#10;    frames = []&#10;    for ts_str in timestamps:&#10;        frame_traces = []&#10;&#10;        # ====== SUBPLOT 1: Temperature &amp; Humidity ======&#10;        # Add model traces (temperature)&#10;        for model in MODEL_ORDER:&#10;            if ts_str in model_data.get(model, {}):&#10;                temp, height = model_data[model][ts_str]&#10;                line_dash = icon_2te_hatpro_linestyle if model == &quot;ICON2TE&quot; else &quot;solid&quot;&#10;                frame_traces.append(go.Scatter(x=temp, y=height, mode='lines', name=model,&#10;                                               line=dict(color=model_colors_temp_wind[model], dash=line_dash,&#10;                                                         width=1.5), legendgroup=model,&#10;                                               showlegend=True, xaxis='x1', yaxis='y1'))&#10;&#10;                # Add CAP marker&#10;                if ts_str in cap_data.get(model, {}):&#10;                    temp_cap, height_cap = cap_data[model][ts_str]&#10;                    frame_traces.append(go.Scatter(x=[temp_cap], y=[height_cap], mode='markers',&#10;                                                   marker=dict(symbol='x', size=8, color=model_colors_temp_wind[model],&#10;                                                               line=dict(width=0.5,&#10;                                                                         color=model_colors_temp_wind[model])),&#10;                                                   name=f&quot;{model} CAP&quot;,&#10;                                                   legendgroup=model, showlegend=False,&#10;                                                   hovertemplate=f&quot;{model} CAP: {height_cap:.0f}m&lt;extra&gt;&lt;/extra&gt;&quot;,&#10;                                                   xaxis='x1', yaxis='y1'))&#10;&#10;            # Add specific humidity traces (on secondary x-axis x3 = top of subplot 1)&#10;            if ts_str in model_humidity_data.get(model, {}):&#10;                q, height = model_humidity_data[model][ts_str]&#10;                line_dash = icon_2te_hatpro_linestyle if model == &quot;ICON2TE&quot; else &quot;solid&quot;&#10;&#10;                frame_traces.append(go.Scatter(x=q, y=height, mode='lines', name=f&quot;{model} q&quot;,&#10;                                               line=dict(color=model_colors_humidity[model], dash=line_dash, width=1.0),&#10;                                               legendgroup=model,&#10;                                               showlegend=False, xaxis='x3', yaxis='y1'))&#10;&#10;        # Add observations (only for Innsbruck points; names in confg always start with &quot;ibk&quot;) - subplot 1&#10;        if point_name.startswith(&quot;ibk&quot;):&#10;            # Add Radiosonde: all variables but only 1 measurement at 02:15 UTC&#10;            if &quot;radiosonde&quot; in obs_data:&#10;                temp, height = obs_data[&quot;radiosonde&quot;]&#10;                frame_traces.append(go.Scatter(x=temp, y=height, mode='lines', name=&quot;Radiosonde (from 02:18 UTC)&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;Radiosonde&quot;], width=1.5),&#10;                                               legendgroup=&quot;Radiosonde&quot;,&#10;                                               showlegend=True, xaxis='x1', yaxis='y1'))&#10;&#10;                if &quot;radiosonde_cap&quot; in obs_data:&#10;                    temp_cap, height_cap = obs_data[&quot;radiosonde_cap&quot;]&#10;                    frame_traces.append(go.Scatter(x=[temp_cap], y=[height_cap], mode='markers',&#10;                                                   marker=dict(symbol='x', size=8,&#10;                                                               color=model_colors_temp_wind[&quot;Radiosonde&quot;],&#10;                                                               line=dict(width=0.5,&#10;                                                                         color=model_colors_temp_wind[&quot;Radiosonde&quot;])),&#10;                                                   name=&quot;Radiosonde CAP&quot;, legendgroup=&quot;Radiosonde&quot;, showlegend=False,&#10;                                                   hovertemplate=f&quot;Radiosonde CAP: {height_cap:.0f}m&lt;extra&gt;&lt;/extra&gt;&quot;,&#10;                                                   xaxis='x1', yaxis='y1'))&#10;            # Add Radiosonde humidity&#10;            if &quot;radiosonde_humidity&quot; in obs_data:&#10;                q, height = obs_data[&quot;radiosonde_humidity&quot;]&#10;                frame_traces.append(&#10;                    go.Scatter(x=q, y=height, mode='lines', name=&quot;Radiosonde q&quot;,&#10;                               line=dict(color=model_colors_humidity[&quot;Radiosonde&quot;], width=1.0),&#10;                               legendgroup=&quot;Radiosonde&quot;, showlegend=False, xaxis='x3', yaxis='y1'))&#10;&#10;            # HATPRO (time-dependent)&#10;            if &quot;hatpro&quot; in obs_data and ts_str in obs_data[&quot;hatpro&quot;]:&#10;                temp, height = obs_data[&quot;hatpro&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=temp, y=height, mode='lines', name=&quot;HATPRO&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;HATPRO&quot;], width=2.0, dash=&quot;dot&quot;),&#10;                                               legendgroup=&quot;HATPRO&quot;,&#10;                                               showlegend=True, xaxis='x1', yaxis='y1'))&#10;&#10;                cap_key = f&quot;hatpro_cap_{ts_str}&quot;&#10;                if cap_key in obs_data:&#10;                    temp_cap, height_cap = obs_data[cap_key]&#10;                    frame_traces.append(go.Scatter(x=[temp_cap], y=[height_cap], mode='markers',&#10;                                                   marker=dict(symbol='x', size=8,&#10;                                                               color=model_colors_temp_wind[&quot;HATPRO&quot;],&#10;                                                               line=dict(width=0.8,&#10;                                                                         color=model_colors_temp_wind[&quot;HATPRO&quot;])),&#10;                                                   name=&quot;HATPRO CAP&quot;,&#10;                                                   legendgroup=&quot;HATPRO&quot;, showlegend=False,&#10;                                                   hovertemplate=f&quot;HATPRO CAP: {height_cap:.0f}m&lt;extra&gt;&lt;/extra&gt;&quot;,&#10;                                                   xaxis='x1', yaxis='y1'))&#10;&#10;            # HATPRO humidity (time-dependent)&#10;            if &quot;hatpro_humidity&quot; in obs_data and ts_str in obs_data[&quot;hatpro_humidity&quot;]:&#10;                q, height = obs_data[&quot;hatpro_humidity&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=q, y=height, mode='lines', name=&quot;HATPRO q&quot;,&#10;                                               line=dict(color=model_colors_humidity[&quot;HATPRO&quot;], width=1, dash=&quot;dot&quot;),&#10;                                               legendgroup=&quot;HATPRO&quot;,&#10;                                               showlegend=False, xaxis='x3', yaxis='y1'))&#10;&#10;        # ====== SUBPLOT 2: Wind Speed &amp; Direction ======&#10;        # Add wind speed traces (bottom x-axis of subplot 2) - row=1, col=2&#10;        for model in MODEL_ORDER:&#10;            if ts_str in model_wspd_data.get(model, {}):&#10;                wspd, height = model_wspd_data[model][ts_str]&#10;                line_dash = icon_2te_hatpro_linestyle if model == &quot;ICON2TE&quot; else &quot;solid&quot;&#10;&#10;                frame_traces.append(go.Scatter(x=wspd, y=height, mode='lines', name=f&quot;{model} wspd&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[model], dash=line_dash,&#10;                                                         width=1.5), legendgroup=model,&#10;                                               showlegend=False, xaxis='x2', yaxis='y2'))&#10;&#10;            # Add wind direction traces (top x-axis x4 of subplot 2)&#10;            if ts_str in model_udir_data.get(model, {}):&#10;                wdir, height = model_udir_data[model][ts_str]&#10;&#10;                # Use open circles for ICON2TE to match its dashed line style&#10;                marker_symbol = 'circle-open' if model == &quot;ICON2TE&quot; else 'circle'&#10;&#10;                frame_traces.append(go.Scatter(x=wdir, y=height, mode='markers', name=f&quot;{model} wdir&quot;,&#10;                                               marker=dict(color=model_colors_temp_wind[model], size=5,&#10;                                                           symbol=marker_symbol), legendgroup=model,&#10;                                               showlegend=False, xaxis='x4', yaxis='y2'))&#10;&#10;        # Add observation wind data (only for Innsbruck points) - subplot 2&#10;        if point_name.startswith(&quot;ibk&quot;):&#10;            # Radiosonde wind speed (constant)&#10;            if &quot;radiosonde_wspd&quot; in obs_data:&#10;                wspd, height = obs_data[&quot;radiosonde_wspd&quot;]&#10;                frame_traces.append(go.Scatter(x=wspd, y=height, mode='lines', name=&quot;Radiosonde wspd&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;Radiosonde&quot;], width=1.5),&#10;                                               legendgroup=&quot;Radiosonde&quot;, showlegend=False, xaxis='x2', yaxis='y2'))&#10;&#10;            # Radiosonde wind direction (constant)&#10;            if &quot;radiosonde_udir&quot; in obs_data:&#10;                wdir, height = obs_data[&quot;radiosonde_udir&quot;]&#10;                frame_traces.append(go.Scatter(x=wdir, y=height, mode='markers', name=&quot;Radiosonde wdir&quot;,&#10;                                               marker=dict(color=model_colors_temp_wind[&quot;Radiosonde&quot;], size=5,&#10;                                                           symbol='circle'),&#10;                                               legendgroup=&quot;Radiosonde&quot;, showlegend=False, xaxis='x4', yaxis='y2'))&#10;&#10;            # SL88 LIDAR wind speed (time-dependent)&#10;            if &quot;lidar_wspd&quot; in obs_data and ts_str in obs_data[&quot;lidar_wspd&quot;]:&#10;                wspd, height = obs_data[&quot;lidar_wspd&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=wspd, y=height, mode='lines', name=&quot;SL88 LIDAR&quot;,&#10;                                               line=dict(color=model_colors_temp_wind[&quot;HATPRO&quot;], width=2.0, dash=&quot;dot&quot;),&#10;                                               legendgroup=&quot;SL88_LIDAR&quot;,&#10;                                               showlegend=True, xaxis='x2', yaxis='y2'))&#10;&#10;            # SL88 LIDAR wind direction (time-dependent)&#10;            if &quot;lidar_udir&quot; in obs_data and ts_str in obs_data[&quot;lidar_udir&quot;]:&#10;                wdir, height = obs_data[&quot;lidar_udir&quot;][ts_str]&#10;                frame_traces.append(go.Scatter(x=wdir, y=height, mode='markers', name=&quot;SL88 LIDAR wdir&quot;,&#10;                                               marker=dict(color=model_colors_temp_wind[&quot;HATPRO&quot;], size=5,&#10;                                                           symbol='circle'),&#10;                                               legendgroup=&quot;SL88_LIDAR&quot;, showlegend=False, xaxis='x4', yaxis='y2'))&#10;&#10;        # Format current timestamp for this frame&#10;        formatted_ts = pd.to_datetime(ts_str).strftime('%dth %H:%M')&#10;        frames.append(go.Frame(data=frame_traces, name=ts_str,&#10;                               layout=go.Layout(&#10;                                   title_text=f&quot;Vertical profiles at {point['name']}, {point['height']} m - {formatted_ts} UTC&quot;)))&#10;&#10;    # Add initial data (first timestep)&#10;    for trace in frames[0].data:&#10;        fig.add_trace(trace, row=1, col=1 if trace.xaxis in ['x1', 'x3'] else 2)&#10;&#10;    # Assign frames&#10;    fig.frames = frames&#10;&#10;    # Create slider&#10;    sliders = [dict(active=0, yanchor=&quot;top&quot;, y=-0.12, xanchor=&quot;left&quot;, x=0.1,&#10;                    currentvalue=dict(prefix=&quot;Time: &quot;, visible=True, xanchor=&quot;center&quot;, font=dict(size=14)),&#10;                    pad=dict(b=10, t=50),&#10;                    len=0.8, transition=dict(duration=0), steps=[dict(&#10;            args=[[ts_str], dict(frame=dict(duration=0, redraw=True), mode=&quot;immediate&quot;, transition=dict(duration=0))],&#10;            label=&quot;&quot;,  # Empty label&#10;            method=&quot;animate&quot;) for ts_str in timestamps])]&#10;&#10;    # Update layout&#10;    formatted_ts_initial = pd.to_datetime(timestamps[0]).strftime('%dth %H:%M')&#10;    fig.update_layout(title_text=f&quot;Vertical profiles at {point['name']}, {point['height']} m - {formatted_ts_initial}&quot;,&#10;                      height=700, width=1400, hovermode='closest', template='plotly_white', sliders=sliders,&#10;                      legend=dict(orientation=&quot;h&quot;, yanchor=&quot;top&quot;, y=-0.14, xanchor=&quot;center&quot;, x=0.5,&#10;                                  bgcolor=&quot;rgba(255, 255, 255, 0.8)&quot;, bordercolor=&quot;lightgray&quot;, borderwidth=1),&#10;                      updatemenus=[&#10;                          dict(type=&quot;buttons&quot;, direction=&quot;left&quot;, x=0.0, y=-0.12, xanchor=&quot;left&quot;, yanchor=&quot;top&quot;,&#10;                               pad=dict(t=10, b=10),&#10;                               buttons=[dict(label=&quot;▶ Play&quot;, method=&quot;animate&quot;,&#10;                                             args=[None, dict(frame=dict(duration=800, redraw=True),&#10;                                                              fromcurrent=True, mode=&quot;immediate&quot;,&#10;                                                              transition=dict(duration=0))]),&#10;                                        dict(label=&quot;⏸ Pause&quot;, method=&quot;animate&quot;,&#10;                                             args=[[None], dict(frame=dict(duration=0, redraw=False),&#10;                                                                mode=&quot;immediate&quot;,&#10;                                                                transition=dict(duration=0))])])])&#10;&#10;    # Update x-axes and y-axes&#10;    # Subplot 1 (Temperature &amp; Humidity)&#10;    fig.update_xaxes(title_text=&quot;Temperature [°C]&quot;, range=[8, 20], row=1, col=1)&#10;    fig.update_yaxes(title_text=&quot;Height above terrain [m]&quot;, range=[0, plot_max_height], row=1, col=1)&#10;&#10;    # Subplot 2 (Wind) - no y-axis labels (redundant with left plot), but synchronized zoom&#10;    fig.update_xaxes(title_text=&quot;Wind Speed [m/s]&quot;, range=[0, 10], row=1, col=2)&#10;    fig.update_yaxes(title_text=&quot;&quot;, range=[0, plot_max_height], showticklabels=False, matches='y', row=1, col=2)&#10;&#10;    # Add secondary x-axis for humidity (top of subplot 1) - x3&#10;    fig.update_layout(&#10;        xaxis3=dict(title=&quot;Specific Humidity [g/kg]&quot;, overlaying='x', side='top', range=[0, max_q], anchor='y',&#10;                    showgrid=False))&#10;&#10;    # Add secondary x-axis for wind direction (top of subplot 2) - x4&#10;    fig.update_layout(xaxis4=dict(title=&quot;Wind Direction [°]&quot;, overlaying='x2', side='top', range=[0, 360], anchor='y2',&#10;                                  showgrid=False))&#10;    return fig&#10;&#10;&#10;def plot_save_all_points_with_slider(start_time: str = &quot;2017-10-16T00:00:00&quot;, end_time: str = &quot;2017-10-16T12:00:00&quot;,&#10;                                     time_step_hours: float = 1.0, max_height: float = 5000,&#10;                                     plot_max_height: float = 2000, point_names: List[str] = confg.ALL_POINTS) -&gt; None:&#10;    &quot;&quot;&quot;&#10;    Create and save individual slider plots for each point location.&#10;    &#10;    Creates one HTML file per point, each with its own time slider.&#10;    This is more reliable than trying to animate small multiples.&#10;    &#10;    Args:&#10;        start_time: Start timestamp ISO format (e.g. &quot;2017-10-16T00:00:00&quot;)&#10;        end_time: End timestamp ISO format (e.g. &quot;2017-10-16T12:00:00&quot;)&#10;        time_step_hours: Time step in hours between frames (default: 1.0)&#10;        max_height: Maximum height in meters to load data (default: 5000m)&#10;        plot_max_height: Maximum height in meters to display initially (default: 2000m)&#10;        point_names: List of points to plot (default: confg.ALL_POINTS)&#10;    &quot;&quot;&quot;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;Creating individual slider plots for {len(point_names)} points&quot;)&#10;    print(f&quot;Time range: {start_time} to {end_time}, step: {time_step_hours}h&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;    # Generate list of timestamps&#10;    timestamps = pd.date_range(start=start_time, end=end_time, freq=f&quot;{int(time_step_hours * 60)}min&quot;).strftime(&#10;        &quot;%Y-%m-%dT%H:%M:%S&quot;).tolist()&#10;&#10;    print(f&quot;Total timesteps: {len(timestamps)}\n&quot;)&#10;    # Ensure output directory exists&#10;    html_dir = os.path.join(confg.dir_PLOTS, &quot;vertical_plots&quot;)&#10;    os.makedirs(html_dir, exist_ok=True)&#10;&#10;    # Create plot for each point&#10;    for point_name in point_names:&#10;        try:&#10;            point = confg.ALL_POINTS.get(point_name)&#10;            if point is None:&#10;                print(f&quot;⚠ Skipping {point_name} - not found in confg&quot;)&#10;                continue&#10;&#10;            print(f&quot;\n{'-' * 70}&quot;)&#10;            print(f&quot;Processing: {point['name']} ({point_name})&quot;)&#10;            print(f&quot;{'-' * 70}&quot;)&#10;&#10;            # Create the plot with slider&#10;            fig = plot_single_point_with_slider(point_name, timestamps=timestamps, max_height=max_height,&#10;                                                plot_max_height=plot_max_height)&#10;            # Save to HTML&#10;            html_path = os.path.join(html_dir, f&quot;vertical_profile_{point_name}_slider.html&quot;)&#10;            fig.write_html(html_path)&#10;            print(f&quot;✓ Saved: {html_path}&quot;)&#10;&#10;        except Exception as e:&#10;            print(f&quot;✗ Error processing {point_name}: {e}&quot;)&#10;            continue&#10;&#10;    print(f&quot;\n{'=' * 70}&quot;)&#10;    print(f&quot;✓ All plots created successfully!&quot;)&#10;    print(f&quot;  Location: {html_dir}&quot;)&#10;    print(f&quot;  - Use the slider to move through timesteps&quot;)&#10;    print(f&quot;  - Click 'Play' to animate&quot;)&#10;    print(f&quot;  - Data loaded up to {max_height}m, displayed up to {plot_max_height}m&quot;)&#10;    print(f&quot;{'=' * 70}\n&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Create vertical temperature profile plot for 04:00 UTC on October 16, 2017&#10;    # Data is loaded up to 5000m but initially displayed up to 2000m&#10;    # Users can zoom out in the interactive HTML to see higher altitudes&#10;    # plot_save_vertical_profiles(timestamp=&quot;2017-10-16T04:00:00&quot;, max_height=5000, plot_max_height=2000)&#10;&#10;    # Create interactive plot with time slider&#10;    # Shows profiles from midnight to noon on October 16, 2017&#10;    plot_save_all_points_with_slider(start_time=&quot;2017-10-15T14:00:00&quot;, end_time=&quot;2017-10-16T12:00:00&quot;,&#10;                                     time_step_hours=0.5, max_height=3000, plot_max_height=800, # )&#10;                                     point_names=[&quot;ibk_uni&quot;, &quot;telfs&quot;])" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/confg.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/confg.py" />
              <option name="originalContent" value="&quot;&quot;&quot;In this &quot;confg-script&quot; are all the data filepaths listed&#10;You have to change it!&#10;original by hannes, daniel adapted it a bit and added/edited some coords and definitions that are multiple times used&#10;to avoid double definitions &amp; confusions...&#10;&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;&#10;# -------------------------------------------To change --------------------------------------------------------&#10;# Folder where the model output is saved:&#10;model_folder = os.path.normpath(&quot;D:/MSc_Arbeit&quot;)&#10;# Folder where the data is saved:&#10;data_folder = os.path.join(model_folder, &quot;data&quot;)&#10;# Plot directory (where to save the plots)&#10;dir_PLOTS = os.path.join(model_folder, &quot;plots&quot;)&#10;dir_topo_plots = os.path.join(dir_PLOTS, &quot;topography_comparison&quot;)&#10;&#10;# -------------------------------------------constants needed for calculations---------------------------------&#10;hafelekar_height = 2279  # m, highest HOBO from https://zenodo.org/records/4672313 hobo dataset, used for VHD calc&#10;c_p = 1005  # J/(kg*K), specific heat capacity of air at constant pressure, for VHD calc&#10;&#10;# All point locations defined below (created for Daniel's thesis):&#10;ALL_POINTS = {&quot;ibk_villa&quot;: {&quot;name&quot;: &quot;ibk villa&quot;, &quot;lat&quot;: 47.25971, &quot;lon&quot;: 11.38420, &quot;height&quot;: 579},&#10;              # same lat &amp; lon of Ibk cosma already used: which&#10;              # is for Ibk_Villa (2m temp recording); changed point to coords of https://acinn-data.uibk.ac.at/pages/meteodat.html&#10;              # now 4 m higher as Cosma's point (she had 575m ...)&#10;&#10;              &quot;ibk_uni&quot;: {&quot;name&quot;: &quot;ibk uni&quot;, &quot;lat&quot;: 47.264, &quot;lon&quot;: 11.385, &quot;height&quot;: 612},&#10;              # hatpro, uni coords rounded to 3 digits after comma&#10;              &quot;ibk_airport&quot;: {&quot;name&quot;: &quot;ibk airport&quot;, &quot;lat&quot;: 47.26, &quot;lon&quot;: 11.34, &quot;height&quot;: 577},&#10;              &quot;hafelekar&quot;: {&quot;name&quot;: &quot;hafelekar&quot;, &quot;lat&quot;: 47.312, &quot;lon&quot;: 11.383, &quot;height&quot;: hafelekar_height},&#10;              # 2279m, with 3 digits&#10;              &quot;slope_north_patscherkofel&quot;: {&quot;name&quot;: &quot;slope north patscherkofel&quot;, &quot;lat&quot;: 47.23, &quot;lon&quot;: 11.5,&#10;                                            &quot;height&quot;: 1750},&#10;              &quot;woergl&quot;: {&quot;name&quot;: &quot;woergl&quot;, &quot;lat&quot;: 47.494, &quot;lon&quot;: 12.059, &quot;height&quot;: 504},&#10;              # coords for wörgl (504m), lower Inn valley&#10;              &quot;kiefersfelden&quot;: {&quot;name&quot;: &quot;kiefersfelden&quot;, &quot;lat&quot;: 47.62, &quot;lon&quot;: 12.2, &quot;height&quot;: 480},&#10;              # coords for kiefersfelden (480m), Germany, entrance Inn valley&#10;              &quot;telfs&quot;: {&quot;name&quot;: &quot;telfs&quot;, &quot;lat&quot;: 47.3, &quot;lon&quot;: 11.1, &quot;height&quot;: 622},  # 622m&#10;              # valley points in wipp &amp; ziller valley for stability plots (where valleys are narrow):&#10;              &quot;wipp_valley&quot;: {&quot;name&quot;: &quot;wipp valley&quot;, &quot;lat&quot;: 47.13, &quot;lon&quot;: 11.45, &quot;height&quot;: 1044},&#10;              # between Schönberg &amp; Matrei&#10;              &quot;ziller_valley&quot;: {&quot;name&quot;: &quot;ziller valley&quot;, &quot;lat&quot;: 47.25, &quot;lon&quot;: 11.9, &quot;height&quot;: 565},&#10;              # between Zell am Ziller &amp; Zillertal&#10;              &quot;ziller_ried&quot;: {&quot;name&quot;: &quot;ziller ried&quot;, &quot;lat&quot;: 47.3, &quot;lon&quot;: 11.87, &quot;height&quot;: 572}  # Zillertal, Kaltenbach&#10;              }&#10;POINT_NAMES = list(ALL_POINTS.keys())  # list w. all point names&#10;# coordinates of points used for Daniels' Analysis; all points that should include HATPRO or Radiosonde data in&#10;# the point plots need &quot;ibk&quot; in the beginning of point definition&#10;# heights in m from https://www.freemaptools.com/elevation-finder.htm&#10;&#10;# List of point keys for easy iteration - coordinates of points used for Daniels' Analysis&#10;# Points that should include HATPRO plot (VHD) need &quot;ibk&quot; in name&#10;# Heights in m from https://www.freemaptools.com/elevation-finder.htm&#10;POINT_NAMES = list(ALL_POINTS.keys())&#10;&#10;# Define point categories for easy filtering; hardcoded list to distinguish valley and mountain points&#10;VALLEY_POINTS = [&quot;ibk_villa&quot;, &quot;ibk_uni&quot;, &quot;ibk_airport&quot;, &quot;woergl&quot;, &quot;kiefersfelden&quot;, &quot;telfs&quot;, &quot;wipp_valley&quot;, &quot;ziller_valley&quot;, &quot;ziller_ried&quot;]&#10;MOUNTAIN_SLOPE_POINTS = [&quot;hafelkar&quot;, &quot;slope_north_patscherkofel&quot;]&#10;&#10;def get_valley_points_only():&#10;    &quot;&quot;&quot;Get only valley points (excludes mountains and slopes)&quot;&quot;&quot;&#10;    return {key: value for key, value in ALL_POINTS.items() if key in VALLEY_POINTS}&#10;&#10;def get_points_excluding_mountains():&#10;    &quot;&quot;&quot;Get all points except mountain/slope points&quot;&quot;&quot;&#10;    return {key: value for key, value in ALL_POINTS.items() if key not in MOUNTAIN_SLOPE_POINTS}&#10;&#10;&#10;lat_hf_min, lat_hf_max = 47, 47.6&#10;lon_hf_min, lon_hf_max = 11.1, 12.1&#10;&#10;lat_min_vhd, lat_max_vhd = 47, 47.7  # orig: 47, 47.7    # lat &amp; lon values for vhd domain plotting&#10;lon_min_vhd, lon_max_vhd = 10.8, 12  # 10.8, 12&#10;&#10;lat_min_cap_height, lat_max_cap_height = 47, 48.2&#10;lon_min_cap_height, lon_max_cap_height = 10.6, 13&#10;&#10;lat_min, lat_max = 46.5, 48.2&#10;lon_min, lon_max = 9.2, 13&#10;&#10;# -------------------------------------------------------------------------------------------------------------&#10;radiosonde_folder = os.path.join(data_folder, &quot;Observations&quot;, &quot;Radiosonde&quot;)&#10;radiosonde_csv = os.path.join(radiosonde_folder, &quot;2017101603_bufr309052.csv&quot;)  # radiosonden aufstieg at innsbruck airport&#10;# deprecated: radiosonde_edited = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_2017101603.csv&quot;)  # calculated pot. temp &amp; rho&#10;# from other vars&#10;radiosonde_dataset = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_2017101603.nc&quot;)  # for same handling for plots &amp; calcs  save&#10;# Radiosonde as dataset&#10;# radiosonde_dataset_height_as_z = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_2017101603_height_as_z.nc&quot;)  # deprecated,&#10;# use fct in réad_in_hatpro_radiosonde.py&#10;# only geopot. height instead of &quot;height values&quot;&#10;# deprecated? radiosonde_smoothed = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_smoothed.nc&quot;)&#10;&#10;all_model_topographies = os.path.join(model_folder, &quot;AROME&quot;, &quot;all_model_topographies.nc&quot;)  # all topography-values extracted (lowest&#10;# lvl) of geopot. height + &quot;hgt&quot; - vars for AROME &amp; WRF and put into one file&#10;&#10;JSON_TIROL = os.path.join(data_folder, &quot;Height&quot;, &quot;gadm41_AUT_1.json&quot;)  # tirol json file&#10;DEMFILE_CLIP = os.path.join(data_folder, &quot;Height&quot;, &quot;dem_clipped.tif&quot;)  # dem file (höhe)&#10;TIROL_DEMFILE = os.path.join(data_folder, &quot;Height&quot;, &quot;dem.tif&quot;)  # changed dem file: indexed and renamed coords&#10;dem_smoothed = os.path.join(data_folder, &quot;Height&quot;, &quot;dem_smoothed.tif&quot;)&#10;filepath_arome_height = os.path.join(model_folder, &quot;AROME&quot;, &quot;AROME_TEAMx_CAP_3D_fields&quot;,&#10;                                     &quot;AROME_Geosphere_20171015T1200Z_CAP02_3D_30min_1km_best_z.nc&quot;)&#10;dem_file_hobos_extent = os.path.join(data_folder, &quot;Height&quot;, &quot;dem_cut_hobos.tif&quot;)  # created DEM (in model_topography) to see real&#10;# heights with HOBOS&#10;&#10;# ZAMG Datahub files&#10;kufstein_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_station9016-Kufstein_20171012_20171018.csv&quot;)&#10;innsbruck_uni_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;,&#10;                                  &quot;data_station11803-InnsbruckUniversity_20171012_20171018.csv&quot;)&#10;innsbruck_airport_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;,&#10;                                      &quot;data_station11804-InnsbruckAirport_20171012_20171018.csv&quot;)&#10;jenbach_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_station11901-Jenbach_20171012_20171018.csv&quot;)&#10;rinn_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_station11123-Rinn_20171015T1200_20171016T1210.csv&quot;)&#10;munchen_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_munich_T2m.csv&quot;)&#10;&#10;# mobile stations, cut to our period&#10;momma_our_period_file = os.path.join(data_folder, &quot;Observations&quot;, &quot;MOMMA&quot;, &quot;MOMMA_our_period.nc&quot;)&#10;&#10;# ----------------------------------Models-----------------------------------------------------&#10;&#10;# absolute paths AROME&#10;dir_AROME = os.path.join(model_folder, &quot;AROME&quot;)&#10;dir_2D_AROME = os.path.join(dir_AROME, &quot;AROME_TEAMx_CAP_2D_fields&quot;)&#10;dir_3D_AROME = os.path.join(dir_AROME, &quot;AROME_TEAMx_CAP_3D_fields&quot;)&#10;dir_timeseries_AROME = os.path.join(dir_AROME, &quot;AROME_TEAMx_CAP_timeseries&quot;)&#10;&#10;# absolute paths WRF&#10;wrf_folder = os.path.join(model_folder, &quot;WRF_ACINN&quot;)  # before: wrf_ACINN&#10;&#10;# absolute paths ICON&#10;icon_folder_3D = os.path.join(model_folder, &quot;ICON&quot;)&#10;icon_folder_meteogram = os.path.join(model_folder, &quot;icon&quot;, &quot;ICON_Meteogram&quot;)  # ?&#10;&#10;# absolute paths ICON2TE&#10;icon2TE_folder_3D = os.path.join(model_folder, &quot;ICON2TE&quot;)&#10;&#10;# absolute Path UKMO&#10;ukmo_folder = os.path.join(model_folder, &quot;ukmo&quot;)&#10;&#10;# ------------------------------colormaps for plotting ---------------------------------------------&#10;from colorspace import qualitative_hcl&#10;&#10;# --- Color scheme for models (consistent with plot_cap_height) ---&#10;qualitative_colors_temp = qualitative_hcl(palette=&quot;Dark 3&quot;).colors()&#10;qualitative_colors_wind = qualitative_colors_temp&#10;qualitative_colors_humidity = qualitative_hcl(palette=&quot;Dark 3&quot;).colors()&#10;&#10;# Model color mapping for temperature - ICON and ICON2TE share the same color; take same color for LIDAR88 and HATPRO&#10;model_colors_temp_wind = {&quot;AROME&quot;: qualitative_colors_temp[0], &quot;ICON&quot;: qualitative_colors_temp[2],&#10;                          &quot;ICON2TE&quot;: qualitative_colors_temp[2], &quot;UM&quot;: qualitative_colors_temp[4],&#10;                          &quot;WRF&quot;: qualitative_colors_temp[6], &quot;Radiosonde&quot;: qualitative_colors_temp[10],&#10;                          &quot;HATPRO&quot;: qualitative_colors_temp[8], &quot;LIDAR88&quot;: qualitative_colors_temp[8],&#10;                          &quot;LIDAR142&quot;: qualitative_colors_temp[9]}&#10;&#10;# Model color mapping for humidity&#10;model_colors_humidity = {&quot;AROME&quot;: qualitative_colors_humidity[0], &quot;ICON&quot;: qualitative_colors_humidity[2],&#10;                         &quot;ICON2TE&quot;: qualitative_colors_humidity[2], &quot;UM&quot;: qualitative_colors_humidity[4],&#10;                         &quot;WRF&quot;: qualitative_colors_humidity[6], &quot;Radiosonde&quot;: qualitative_colors_humidity[10],&#10;                         &quot;HATPRO&quot;: qualitative_colors_humidity[8]}&#10;&#10;# define linestyle for ICON2TE&#10;icon_2te_hatpro_linestyle = &quot;dot&quot;&#10;&#10;# -------------------------------Data and Plot paths -----------------------------------------------&#10;&#10;# EC stations&#10;dir_EC_stations = f&quot;{data_folder}/Observations/EC_4_stations&quot;&#10;EC_30min_final = f&quot;{dir_EC_stations}/EC_30min_file.nc&quot;&#10;EC_1min_final = f&quot;{dir_EC_stations}/EC_1min_file.nc&quot;&#10;&#10;# Ibox dir&#10;ibox_folder = f&quot;{data_folder}/Observations/Ibox&quot;&#10;&#10;# HOBOS station&#10;hobos_file = f&quot;{data_folder}/Observations/HOBOS/hobos_final.nc&quot;  # Observations/HOBOS/&#10;&#10;# Lidar obs&#10;lidar_obs_folder = os.path.join(data_folder, &quot;Observations&quot;, &quot;Lidar_obs&quot;)&#10;lidar_sl88 = os.path.join(lidar_obs_folder, &quot;SL88&quot;, &quot;&quot;)  # add trailing separator for consistency&#10;lidar_slxr142 = os.path.join(lidar_obs_folder, &quot;SLXR142_vad_l2&quot;, &quot;&quot;)&#10;# merged files, subsetted to period and 30 min intervals are saved in:&#10;lidar_sl88_merged_path = os.path.join(lidar_sl88, 'sl88_merged.nc')&#10;lidar_slxr142_merged_path = os.path.join(lidar_slxr142, 'slxr142_merged.nc')&#10;&#10;# HATPRO obs&#10;hatpro_folder = os.path.join(data_folder, &quot;Observations&quot;, &quot;HATPRO_obs&quot;)  # nicht vorhanden?&#10;hatpro_merged = os.path.join(hatpro_folder, &quot;hatpro_merged.nc&quot;)  #  + &quot;hatpro_merged.nc&quot;&#10;hatpro_smoothed = os.path.join(hatpro_folder, &quot;hatpro_smoothed.nc&quot;)&#10;hatpro_calced_vars = os.path.join(hatpro_folder, &quot;hatpro_calced_vars_from_arome_p_height_as_z.nc&quot;)&#10;hatpro_with_cap_height = os.path.join(hatpro_folder, &quot;hatpro_interpolated_arome_height_as_z_with_cap_height.nc&quot;)&#10;&#10;# Radiosonde CAP height is 1537 m (searched by hand) - ibk_airport[&quot;height&quot;] = 960 m&#10;radiosonde_cap_height = 1537 - ALL_POINTS[&quot;ibk_airport&quot;][&quot;height&quot;]&#10;# deprecated ones?&#10;# hatpro_interp_arome = hatpro_folder + &quot;hatpro_interpolated_arome.nc&quot;&#10;# hatpro_interp_arome_height_as_z = hatpro_folder + &quot;hatpro_interpolated_arome_height_as_z.nc&quot;&#10;&#10;&#10;# Define colors for the models to use the same in each plot:&#10;colordict = {&quot;HOBOS&quot;: &quot;purple&quot;, &quot;ICON&quot;: &quot;orange&quot;, &quot;RADIOSONDE&quot;: &quot;black&quot;, &quot;AROME&quot;: &quot;red&quot;, &quot;HATPRO&quot;: &quot;gray&quot;,&#10;             &quot;UKMO&quot;: &quot;green&quot;, &quot;WRF_ACINN&quot;: &quot;blue&quot;}&#10;&#10;# Create a dictionary with information of the TAWES stations&#10;station_files_zamg = {&#10;    &quot;IAO&quot;: {&quot;filepath&quot;: innsbruck_uni_zamg, &quot;name&quot;: &quot;Innsbruck Uni&quot;, 'lon': 11.384167, 'lat': 47.259998,&#10;            'hoehe': 578, },&#10;    &quot;JEN&quot;: {&quot;filepath&quot;: jenbach_zamg, &quot;name&quot;: &quot;Jenbach&quot;, 'lat': 47.388889, 'lon': 11.758056, 'hoehe': 530, },&#10;    &quot;KUF&quot;: {&quot;filepath&quot;: kufstein_zamg, &quot;name&quot;: &quot;Kufstein&quot;, 'lon': 12.162778, 'lat': 47.575279, 'hoehe': 490, },&#10;    &quot;LOWI&quot;: {&quot;filepath&quot;: innsbruck_airport_zamg, &quot;name&quot;: &quot;Innsbruck Airport&quot;, 'lat': 47.2598, 'lon': 11.3553,&#10;             'hoehe': 578, }, &quot;IMST&quot;: {  # &quot;filepath&quot;: imst_zamg,&#10;        &quot;name&quot;: &quot;Imst&quot;, 'lat': 47.2419, 'lon': 10.7218, 'hoehe': 828, }}&#10;&#10;# create a dict with info about the IBOX stations&#10;stations_ibox = {&#10;    &quot;VF0&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/vf0.csv&quot;, &quot;name&quot;: &quot;Kolsass&quot;, &quot;latitude&quot;: 47.305, &quot;longitude&quot;: 11.622,&#10;            &quot;height&quot;: 545},&#10;    &quot;SF8&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/sf8.csv&quot;, &quot;name&quot;: &quot;Terfens&quot;, &quot;latitude&quot;: 47.326, &quot;longitude&quot;: 11.652,&#10;            &quot;height&quot;: 575},&#10;    &quot;SF1&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/sf1.csv&quot;, &quot;name&quot;: &quot;Eggen&quot;, &quot;latitude&quot;: 47.317, &quot;longitude&quot;: 11.616,&#10;            &quot;height&quot;: 829},&#10;    &quot;NF10&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/nf10.csv&quot;, &quot;name&quot;: &quot;Weerberg&quot;, &quot;latitude&quot;: 47.300, &quot;longitude&quot;: 11.673,&#10;             &quot;height&quot;: 930},&#10;    &quot;NF27&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/nf27.csv&quot;, &quot;name&quot;: &quot;Hochhaeuser&quot;, &quot;latitude&quot;: 47.288, &quot;longitude&quot;: 11.631,&#10;             &quot;height&quot;: 1009}}&#10;&#10;# dict with infos about EC stations&#10;ec_station_names = {1: {&quot;name&quot;: &quot;Patsch_EC_South&quot;, &quot;lat&quot;: 47.209068, &quot;lon&quot;: 11.411932},&#10;                    0: {&quot;name&quot;: &quot;Innsbruck_Airport_EC_West&quot;, &quot;lat&quot;: 47.255375, &quot;lon&quot;: 11.342832},&#10;                    2: {&quot;name&quot;: &quot;Thaur_EC_East&quot;, &quot;lat&quot;: 47.281335, &quot;lon&quot;: 11.474532},&#10;                    3: {&quot;name&quot;: &quot;IAO_Centre_Innsbruck_EC_Center&quot;, &quot;lat&quot;: 47.264035, &quot;lon&quot;: 11.385707}}&#10;&#10;# variables, units 2D AROME&#10;variables_units_2D_AROME = {'hfs': 'W/m²',  # Sensible heat flux at the surface&#10;                            'hgt': 'm',  # Surface geopotential height&#10;                            'lfs': 'W/m²',  # Latent heat flux at the surface&#10;                            'lwd': 'W/m²',  # Longwave incoming radiation at the surface&#10;                            'lwnet': 'W/m²',  # Longwave net radiation at the surface&#10;                            'lwu': 'W/m²',  # Longwave outgoing radiation at the surface (derived: lwnet - lwd)&#10;                            'pre': 'kg/m²',  # Surface precipitation (same as mm)&#10;                            'ps': 'Pa',  # Surface pressure&#10;                            'swd': 'W/m²',  # Shortwave incoming radiation at the surface&#10;                            'swnet': 'W/m²',  # Shortwave net radiation at the surface&#10;                            'swu': 'W/m²',  # Shortwave reflected radiation at the surface (derived: swnet - swd)&#10;                            'tsk': 'K'  # Surface temperature (Oberflächentemperatur)&#10;                            }&#10;&#10;# variables, units 3D AROME&#10;variables_units_3D_AROME = {'ciwc': 'kg/kg',  # Specific cloud ice water content&#10;                            'clwc': 'kg/kg',  # Specific cloud liquid water content&#10;                            'p': 'Pa',  # Pressure&#10;                            'q': 'kg/kg',  # Specific humidity&#10;                            'th': 'K',  # Potential temperature&#10;                            'tke': 'm²/s²',  # Turbulent kinetic energy&#10;                            'u': 'm/s',  # Zonal wind component&#10;                            'v': 'm/s',  # Meridional wind component&#10;                            'w': 'm/s',  # Vertical wind velocity&#10;                            'z': 'm',  # Geopotential height&#10;                            }&#10;&#10;# Define colors for the cities, used e.g. in temperature timeseries&#10;cities = {&#10;    'Innsbruck Uni': {'lon': 11.384167, 'lat': 47.259998, 'csv': innsbruck_uni_zamg, 'color': &quot;red&quot;, 'hoehe': 578, },&#10;    'Kufstein': {'lon': 12.162778, 'lat': 47.575279, 'csv': kufstein_zamg, 'color': &quot;blue&quot;, 'hoehe': 490, },&#10;    'Innsbruck Airport': {'lat': 47.2598, 'lon': 11.3553, 'csv': innsbruck_airport_zamg, 'color': &quot;green&quot;,&#10;                          'hoehe': 578, },&#10;    'Jenbach': {'lat': 47.388889, 'lon': 11.758056, 'csv': jenbach_zamg, 'color': &quot;gray&quot;, 'hoehe': 530, },&#10;    'Rinn': {'lat': 47.249168, 'lon': 11.503889, 'csv': rinn_zamg, 'color': &quot;purple&quot;, 'hoehe': 924},&#10;    'Muenchen': {'lat': 48.149723, 'lon': 11.540523, 'color': &quot;orange&quot;, 'hoehe': 521, 'csv': munchen_zamg&#10;                 # Replace 'munchen_zamg' with the actual path to your CSV file if you have data for München&#10;                 }}&#10;&#10;# information about MOMMA stations&#10;MOMMA_stations = {&quot;0&quot;: &quot;Völs&quot;, &quot;1&quot;: &quot;Innsbruck_Bergisel&quot;, &quot;2&quot;: &quot;Patsch_Pfaffenbichl&quot;, &quot;3&quot;: &quot;Innsbruck_Ölberg&quot;,&#10;                  &quot;4&quot;: &quot;Innsbruck_Hotel Hilton&quot;, &quot;5&quot;: &quot;Innsbruck_Saggen_Kettenbrücke&quot;, &quot;6&quot;: &quot;Volders&quot;,&#10;                  &quot;7&quot;: &quot;Unterperfuss&quot;, &quot;8&quot;: &quot;Inzing_Zirl_Modellflugplatz&quot;}&#10;&#10;MOMMA_stations_PM = {&#10;    &quot;PM02&quot;: {&quot;name&quot;: &quot;Völs&quot;, &quot;latitude&quot;: 47.2614791608, &quot;longitude&quot;: 11.3117537274, &quot;height&quot;: 583, &quot;key&quot;: 0},&#10;    &quot;PM03&quot;: {&quot;name&quot;: &quot;Innsbruck_Bergisel&quot;, &quot;latitude&quot;: 47.2472604421, &quot;longitude&quot;: 11.3986000093, &quot;height&quot;: 726,&#10;             &quot;key&quot;: 1},&#10;    &quot;PM04&quot;: {&quot;name&quot;: &quot;Patsch_Pfaffenbichl&quot;, &quot;latitude&quot;: 47.21030188, &quot;longitude&quot;: 11.4105114057, &quot;height&quot;: 983,&#10;             &quot;key&quot;: 2},&#10;    &quot;PM05&quot;: {&quot;name&quot;: &quot;Innsbruck_Ölberg&quot;, &quot;latitude&quot;: 47.2784241867, &quot;longitude&quot;: 11.3902967638, &quot;height&quot;: 722,&#10;             &quot;key&quot;: 3},&#10;    &quot;PM06&quot;: {&quot;name&quot;: &quot;Innsbruck_Hotel Hilton&quot;, &quot;latitude&quot;: 47.2620425014, &quot;longitude&quot;: 11.3959606669, &quot;height&quot;: 629,&#10;             &quot;key&quot;: 4},&#10;    &quot;PM07&quot;: {&quot;name&quot;: &quot;Innsbruck_Saggen_Kettenbrücke&quot;, &quot;latitude&quot;: 47.2787431973, &quot;longitude&quot;: 11.4123320657,&#10;             &quot;height&quot;: 569, &quot;key&quot;: 5},&#10;    &quot;PM08&quot;: {&quot;name&quot;: &quot;Volders&quot;, &quot;latitude&quot;: 47.2930516284, &quot;longitude&quot;: 11.5697988436, &quot;height&quot;: 552, &quot;key&quot;: 6},&#10;    &quot;PM09&quot;: {&quot;name&quot;: &quot;Unterperfuss&quot;, &quot;latitude&quot;: 47.2615210341, &quot;longitude&quot;: 11.2607050096, &quot;height&quot;: 594, &quot;key&quot;: 7},&#10;    &quot;PM10&quot;: {&quot;name&quot;: &quot;Inzing_Zirl_Modellflugplatz&quot;, &quot;latitude&quot;: 47.2744017492, &quot;longitude&quot;: 11.2143291427,&#10;             &quot;height&quot;: 597, &quot;key&quot;: 8}}&#10;&#10;# units of lidar observations&#10;vars_lidar = {'u': 'm/s', 'v': 'm/s', 'w': 'm/s', 'ff': 'm/s', 'dd': 'degree'}&#10;&#10;# hatpro height information&#10;hatpro_vertical_levels = {&#10;    &quot;height_name&quot;: [&quot;V01&quot;, &quot;V02&quot;, &quot;V03&quot;, &quot;V04&quot;, &quot;V05&quot;, &quot;V06&quot;, &quot;V07&quot;, &quot;V08&quot;, &quot;V09&quot;, &quot;V10&quot;, &quot;V11&quot;, &quot;V12&quot;, &quot;V13&quot;, &quot;V14&quot;,&#10;                    &quot;V15&quot;, &quot;V16&quot;, &quot;V17&quot;, &quot;V18&quot;, &quot;V19&quot;, &quot;V20&quot;, &quot;V21&quot;, &quot;V22&quot;, &quot;V23&quot;, &quot;V24&quot;, &quot;V25&quot;, &quot;V26&quot;, &quot;V27&quot;, &quot;V28&quot;,&#10;                    &quot;V29&quot;, &quot;V30&quot;, &quot;V31&quot;, &quot;V32&quot;, &quot;V33&quot;, &quot;V34&quot;, &quot;V35&quot;, &quot;V36&quot;, &quot;V37&quot;, &quot;V38&quot;, &quot;V39&quot;],&#10;    &quot;height&quot;: [&quot;0&quot;, &quot;10&quot;, &quot;30&quot;, &quot;50&quot;, &quot;75&quot;, &quot;100&quot;, &quot;125&quot;, &quot;150&quot;, &quot;200&quot;, &quot;250&quot;, &quot;325&quot;, &quot;400&quot;, &quot;475&quot;, &quot;550&quot;, &quot;625&quot;, &quot;700&quot;,&#10;               &quot;800&quot;, &quot;900&quot;, &quot;1000&quot;, &quot;1150&quot;, &quot;1300&quot;, &quot;1450&quot;, &quot;1600&quot;, &quot;1800&quot;, &quot;2000&quot;, &quot;2200&quot;, &quot;2500&quot;, &quot;2800&quot;, &quot;3100&quot;,&#10;               &quot;3500&quot;, &quot;3900&quot;, &quot;4400&quot;, &quot;5000&quot;, &quot;5600&quot;, &quot;6200&quot;, &quot;7000&quot;, &quot;8000&quot;, &quot;9000&quot;, &quot;10000&quot;]}&#10;&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;In this &quot;confg-script&quot; are all the data filepaths listed&#10;You have to change it!&#10;original by hannes, daniel adapted it a bit and added/edited some coords and definitions that are multiple times used&#10;to avoid double definitions &amp; confusions...&#10;&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;&#10;# -------------------------------------------To change --------------------------------------------------------&#10;# Folder where the model output is saved:&#10;model_folder = os.path.normpath(&quot;D:/MSc_Arbeit&quot;)&#10;# Folder where the data is saved:&#10;data_folder = os.path.join(model_folder, &quot;data&quot;)&#10;# Plot directory (where to save the plots)&#10;dir_PLOTS = os.path.join(model_folder, &quot;plots&quot;)&#10;dir_topo_plots = os.path.join(dir_PLOTS, &quot;topography_comparison&quot;)&#10;&#10;# -------------------------------------------constants needed for calculations---------------------------------&#10;hafelekar_height = 2279  # m, highest HOBO from https://zenodo.org/records/4672313 hobo dataset, used for VHD calc&#10;c_p = 1005  # J/(kg*K), specific heat capacity of air at constant pressure, for VHD calc&#10;&#10;# All point locations defined below (created for Daniel's thesis):&#10;ALL_POINTS = {&quot;ibk_villa&quot;: {&quot;name&quot;: &quot;ibk villa&quot;, &quot;lat&quot;: 47.25971, &quot;lon&quot;: 11.38420, &quot;height&quot;: 579},&#10;              # same lat &amp; lon of Ibk cosma already used: which&#10;              # is for Ibk_Villa (2m temp recording); changed point to coords of https://acinn-data.uibk.ac.at/pages/meteodat.html&#10;              # now 4 m higher as Cosma's point (she had 575m ...)&#10;&#10;              &quot;ibk_uni&quot;: {&quot;name&quot;: &quot;ibk uni&quot;, &quot;lat&quot;: 47.264, &quot;lon&quot;: 11.385, &quot;height&quot;: 612},&#10;              # hatpro, uni coords rounded to 3 digits after comma&#10;              &quot;ibk_airport&quot;: {&quot;name&quot;: &quot;ibk airport&quot;, &quot;lat&quot;: 47.26, &quot;lon&quot;: 11.34, &quot;height&quot;: 577},&#10;              &quot;hafelekar&quot;: {&quot;name&quot;: &quot;hafelekar&quot;, &quot;lat&quot;: 47.312, &quot;lon&quot;: 11.383, &quot;height&quot;: hafelekar_height},&#10;              # 2279m, with 3 digits&#10;              &quot;slope_north_patscherkofel&quot;: {&quot;name&quot;: &quot;slope north patscherkofel&quot;, &quot;lat&quot;: 47.23, &quot;lon&quot;: 11.5,&#10;                                            &quot;height&quot;: 1750},&#10;              &quot;woergl&quot;: {&quot;name&quot;: &quot;woergl&quot;, &quot;lat&quot;: 47.494, &quot;lon&quot;: 12.059, &quot;height&quot;: 504},&#10;              # coords for wörgl (504m), lower Inn valley&#10;              &quot;kiefersfelden&quot;: {&quot;name&quot;: &quot;kiefersfelden&quot;, &quot;lat&quot;: 47.62, &quot;lon&quot;: 12.2, &quot;height&quot;: 480},&#10;              # coords for kiefersfelden (480m), Germany, entrance Inn valley&#10;              &quot;telfs&quot;: {&quot;name&quot;: &quot;telfs&quot;, &quot;lat&quot;: 47.3, &quot;lon&quot;: 11.1, &quot;height&quot;: 622},  # 622m&#10;              # valley points in wipp &amp; ziller valley for stability plots (where valleys are narrow):&#10;              &quot;wipp_valley&quot;: {&quot;name&quot;: &quot;wipp valley&quot;, &quot;lat&quot;: 47.13, &quot;lon&quot;: 11.45, &quot;height&quot;: 1044},&#10;              # between Schönberg &amp; Matrei&#10;              &quot;ziller_valley&quot;: {&quot;name&quot;: &quot;ziller valley&quot;, &quot;lat&quot;: 47.25, &quot;lon&quot;: 11.9, &quot;height&quot;: 565},&#10;              # between Zell am Ziller &amp; Zillertal&#10;              &quot;ziller_ried&quot;: {&quot;name&quot;: &quot;ziller ried&quot;, &quot;lat&quot;: 47.3, &quot;lon&quot;: 11.87, &quot;height&quot;: 572}  # Zillertal, Kaltenbach&#10;              }&#10;POINT_NAMES = list(ALL_POINTS.keys())  # list w. all point names&#10;# coordinates of points used for Daniels' Analysis; all points that should include HATPRO or Radiosonde data in&#10;# the point plots need &quot;ibk&quot; in the beginning of point definition&#10;# heights in m from https://www.freemaptools.com/elevation-finder.htm&#10;&#10;# List of point keys for easy iteration - coordinates of points used for Daniels' Analysis&#10;# Points that should include HATPRO plot (VHD) need &quot;ibk&quot; in name&#10;# Heights in m from https://www.freemaptools.com/elevation-finder.htm&#10;POINT_NAMES = list(ALL_POINTS.keys())&#10;&#10;# Define point categories for easy filtering; hardcoded list to distinguish valley and mountain points&#10;VALLEY_POINTS = [&quot;ibk_villa&quot;, &quot;ibk_uni&quot;, &quot;ibk_airport&quot;, &quot;woergl&quot;, &quot;kiefersfelden&quot;, &quot;telfs&quot;, &quot;wipp_valley&quot;, &quot;ziller_valley&quot;, &quot;ziller_ried&quot;]&#10;MOUNTAIN_SLOPE_POINTS = [&quot;hafelkar&quot;, &quot;slope_north_patscherkofel&quot;]&#10;&#10;def get_valley_points_only():&#10;    &quot;&quot;&quot;Get only valley points (excludes mountains and slopes)&quot;&quot;&quot;&#10;    return {key: value for key, value in ALL_POINTS.items() if key in VALLEY_POINTS}&#10;&#10;def get_points_excluding_mountains():&#10;    &quot;&quot;&quot;Get all points except mountain/slope points&quot;&quot;&quot;&#10;    return {key: value for key, value in ALL_POINTS.items() if key not in MOUNTAIN_SLOPE_POINTS}&#10;&#10;&#10;lat_hf_min, lat_hf_max = 47, 47.6&#10;lon_hf_min, lon_hf_max = 11.1, 12.1&#10;&#10;lat_min_vhd, lat_max_vhd = 47, 47.7  # orig: 47, 47.7    # lat &amp; lon values for vhd domain plotting&#10;lon_min_vhd, lon_max_vhd = 10.8, 12  # 10.8, 12&#10;&#10;lat_min_cap_height, lat_max_cap_height = 47, 48.2&#10;lon_min_cap_height, lon_max_cap_height = 10.6, 13&#10;&#10;lat_min, lat_max = 46.5, 48.2&#10;lon_min, lon_max = 9.2, 13&#10;&#10;# -------------------------------------------------------------------------------------------------------------&#10;radiosonde_folder = os.path.join(data_folder, &quot;Observations&quot;, &quot;Radiosonde&quot;)&#10;radiosonde_csv = os.path.join(radiosonde_folder, &quot;2017101603_bufr309052.csv&quot;)  # radiosonden aufstieg at innsbruck airport&#10;# deprecated: radiosonde_edited = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_2017101603.csv&quot;)  # calculated pot. temp &amp; rho&#10;# from other vars&#10;radiosonde_dataset = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_2017101603.nc&quot;)  # for same handling for plots &amp; calcs  save&#10;# Radiosonde as dataset&#10;# radiosonde_dataset_height_as_z = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_2017101603_height_as_z.nc&quot;)  # deprecated,&#10;# use fct in réad_in_hatpro_radiosonde.py&#10;# only geopot. height instead of &quot;height values&quot;&#10;# deprecated? radiosonde_smoothed = os.path.join(radiosonde_folder, &quot;radiosonde_ibk_smoothed.nc&quot;)&#10;&#10;all_model_topographies = os.path.join(model_folder, &quot;AROME&quot;, &quot;all_model_topographies.nc&quot;)  # all topography-values extracted (lowest&#10;# lvl) of geopot. height + &quot;hgt&quot; - vars for AROME &amp; WRF and put into one file&#10;&#10;JSON_TIROL = os.path.join(data_folder, &quot;Height&quot;, &quot;gadm41_AUT_1.json&quot;)  # tirol json file&#10;DEMFILE_CLIP = os.path.join(data_folder, &quot;Height&quot;, &quot;dem_clipped.tif&quot;)  # dem file (höhe)&#10;TIROL_DEMFILE = os.path.join(data_folder, &quot;Height&quot;, &quot;dem.tif&quot;)  # changed dem file: indexed and renamed coords&#10;dem_smoothed = os.path.join(data_folder, &quot;Height&quot;, &quot;dem_smoothed.tif&quot;)&#10;filepath_arome_height = os.path.join(model_folder, &quot;AROME&quot;, &quot;AROME_TEAMx_CAP_3D_fields&quot;,&#10;                                     &quot;AROME_Geosphere_20171015T1200Z_CAP02_3D_30min_1km_best_z.nc&quot;)&#10;dem_file_hobos_extent = os.path.join(data_folder, &quot;Height&quot;, &quot;dem_cut_hobos.tif&quot;)  # created DEM (in model_topography) to see real&#10;# heights with HOBOS&#10;&#10;# ZAMG Datahub files&#10;kufstein_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_station9016-Kufstein_20171012_20171018.csv&quot;)&#10;innsbruck_uni_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;,&#10;                                  &quot;data_station11803-InnsbruckUniversity_20171012_20171018.csv&quot;)&#10;innsbruck_airport_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;,&#10;                                      &quot;data_station11804-InnsbruckAirport_20171012_20171018.csv&quot;)&#10;jenbach_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_station11901-Jenbach_20171012_20171018.csv&quot;)&#10;rinn_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_station11123-Rinn_20171015T1200_20171016T1210.csv&quot;)&#10;munchen_zamg = os.path.join(data_folder, &quot;Observations&quot;, &quot;ZAMG_Tawes&quot;, &quot;data_munich_T2m.csv&quot;)&#10;&#10;# mobile stations, cut to our period&#10;momma_our_period_file = os.path.join(data_folder, &quot;Observations&quot;, &quot;MOMMA&quot;, &quot;MOMMA_our_period.nc&quot;)&#10;&#10;# ----------------------------------Models-----------------------------------------------------&#10;&#10;# absolute paths AROME&#10;dir_AROME = os.path.join(model_folder, &quot;AROME&quot;)&#10;dir_2D_AROME = os.path.join(dir_AROME, &quot;AROME_TEAMx_CAP_2D_fields&quot;)&#10;dir_3D_AROME = os.path.join(dir_AROME, &quot;AROME_TEAMx_CAP_3D_fields&quot;)&#10;dir_timeseries_AROME = os.path.join(dir_AROME, &quot;AROME_TEAMx_CAP_timeseries&quot;)&#10;&#10;# absolute paths WRF&#10;wrf_folder = os.path.join(model_folder, &quot;WRF_ACINN&quot;)  # before: wrf_ACINN&#10;&#10;# absolute paths ICON&#10;icon_folder_3D = os.path.join(model_folder, &quot;ICON&quot;)&#10;icon_folder_meteogram = os.path.join(model_folder, &quot;icon&quot;, &quot;ICON_Meteogram&quot;)  # ?&#10;&#10;# absolute paths ICON2TE&#10;icon2TE_folder_3D = os.path.join(model_folder, &quot;ICON2TE&quot;)&#10;&#10;# absolute Path UKMO&#10;ukmo_folder = os.path.join(model_folder, &quot;ukmo&quot;)&#10;&#10;# ------------------------------colormaps for plotting ---------------------------------------------&#10;from colorspace import qualitative_hcl&#10;&#10;# --- Color scheme for models (consistent with plot_cap_height) ---&#10;qualitative_colors_temp = qualitative_hcl(palette=&quot;Dark 3&quot;).colors()&#10;qualitative_colors_wind = qualitative_colors_temp&#10;qualitative_colors_humidity = qualitative_hcl(palette=&quot;Dark 3&quot;).colors()&#10;&#10;# Model color mapping for temperature - ICON and ICON2TE share the same color; take same color for LIDAR88 and HATPRO&#10;model_colors_temp_wind = {&quot;AROME&quot;: qualitative_colors_temp[0], &quot;ICON&quot;: qualitative_colors_temp[2],&#10;                          &quot;ICON2TE&quot;: qualitative_colors_temp[2], &quot;UM&quot;: qualitative_colors_temp[4],&#10;                          &quot;WRF&quot;: qualitative_colors_temp[6], &quot;Radiosonde&quot;: qualitative_colors_temp[10],&#10;                          &quot;HATPRO&quot;: qualitative_colors_temp[8], &quot;LIDAR88&quot;: qualitative_colors_temp[8],&#10;                          &quot;LIDAR142&quot;: qualitative_colors_temp[9]}&#10;&#10;# Model color mapping for humidity&#10;model_colors_humidity = {&quot;AROME&quot;: qualitative_colors_humidity[0], &quot;ICON&quot;: qualitative_colors_humidity[2],&#10;                         &quot;ICON2TE&quot;: qualitative_colors_humidity[2], &quot;UM&quot;: qualitative_colors_humidity[4],&#10;                         &quot;WRF&quot;: qualitative_colors_humidity[6], &quot;Radiosonde&quot;: qualitative_colors_humidity[10],&#10;                         &quot;HATPRO&quot;: qualitative_colors_humidity[8]}&#10;&#10;# define linestyle for ICON2TE&#10;icon_2te_hatpro_linestyle = &quot;dot&quot;&#10;&#10;# -------------------------------Data and Plot paths -----------------------------------------------&#10;&#10;# EC stations&#10;dir_EC_stations = f&quot;{data_folder}/Observations/EC_4_stations&quot;&#10;EC_30min_final = f&quot;{dir_EC_stations}/EC_30min_file.nc&quot;&#10;EC_1min_final = f&quot;{dir_EC_stations}/EC_1min_file.nc&quot;&#10;&#10;# Ibox dir&#10;ibox_folder = f&quot;{data_folder}/Observations/Ibox&quot;&#10;&#10;# HOBOS station&#10;hobos_file = f&quot;{data_folder}/Observations/HOBOS/hobos_final.nc&quot;  # Observations/HOBOS/&#10;&#10;# Lidar obs&#10;lidar_obs_folder = os.path.join(data_folder, &quot;Observations&quot;, &quot;Lidar_obs&quot;)&#10;lidar_sl88 = os.path.join(lidar_obs_folder, &quot;SL88&quot;, &quot;&quot;)  # add trailing separator for consistency&#10;lidar_slxr142 = os.path.join(lidar_obs_folder, &quot;SLXR142_vad_l2&quot;, &quot;&quot;)&#10;# merged files, subsetted to period and 30 min intervals are saved in:&#10;lidar_sl88_merged_path = os.path.join(lidar_sl88, 'sl88_merged.nc')&#10;lidar_slxr142_merged_path = os.path.join(lidar_slxr142, 'slxr142_merged.nc')&#10;&#10;# HATPRO obs&#10;hatpro_folder = os.path.join(data_folder, &quot;Observations&quot;, &quot;HATPRO_obs&quot;)  # nicht vorhanden?&#10;hatpro_merged = os.path.join(hatpro_folder, &quot;hatpro_merged.nc&quot;)  #  + &quot;hatpro_merged.nc&quot;&#10;hatpro_smoothed = os.path.join(hatpro_folder, &quot;hatpro_smoothed.nc&quot;)&#10;hatpro_calced_vars = os.path.join(hatpro_folder, &quot;hatpro_calced_vars_from_arome_p_height_as_z.nc&quot;)&#10;hatpro_with_cap_height = os.path.join(hatpro_folder, &quot;hatpro_interpolated_arome_height_as_z_with_cap_height.nc&quot;)&#10;&#10;# Radiosonde CAP height is 1537 m (searched by hand) - ibk_airport[&quot;height&quot;] = 960 m&#10;radiosonde_cap_height = 1537 - ALL_POINTS[&quot;ibk_airport&quot;][&quot;height&quot;]&#10;# deprecated ones?&#10;# hatpro_interp_arome = hatpro_folder + &quot;hatpro_interpolated_arome.nc&quot;&#10;# hatpro_interp_arome_height_as_z = hatpro_folder + &quot;hatpro_interpolated_arome_height_as_z.nc&quot;&#10;&#10;&#10;# Define colors for the models to use the same in each plot:&#10;colordict = {&quot;HOBOS&quot;: &quot;purple&quot;, &quot;ICON&quot;: &quot;orange&quot;, &quot;RADIOSONDE&quot;: &quot;black&quot;, &quot;AROME&quot;: &quot;red&quot;, &quot;HATPRO&quot;: &quot;gray&quot;,&#10;             &quot;UKMO&quot;: &quot;green&quot;, &quot;WRF_ACINN&quot;: &quot;blue&quot;}&#10;&#10;# Create a dictionary with information of the TAWES stations&#10;station_files_zamg = {&#10;    &quot;IAO&quot;: {&quot;filepath&quot;: innsbruck_uni_zamg, &quot;name&quot;: &quot;Innsbruck Uni&quot;, 'lon': 11.384167, 'lat': 47.259998,&#10;            'hoehe': 578, },&#10;    &quot;JEN&quot;: {&quot;filepath&quot;: jenbach_zamg, &quot;name&quot;: &quot;Jenbach&quot;, 'lat': 47.388889, 'lon': 11.758056, 'hoehe': 530, },&#10;    &quot;KUF&quot;: {&quot;filepath&quot;: kufstein_zamg, &quot;name&quot;: &quot;Kufstein&quot;, 'lon': 12.162778, 'lat': 47.575279, 'hoehe': 490, },&#10;    &quot;LOWI&quot;: {&quot;filepath&quot;: innsbruck_airport_zamg, &quot;name&quot;: &quot;Innsbruck Airport&quot;, 'lat': 47.2598, 'lon': 11.3553,&#10;             'hoehe': 578, }, &quot;IMST&quot;: {  # &quot;filepath&quot;: imst_zamg,&#10;        &quot;name&quot;: &quot;Imst&quot;, 'lat': 47.2419, 'lon': 10.7218, 'hoehe': 828, }}&#10;&#10;# create a dict with info about the IBOX stations&#10;stations_ibox = {&#10;    &quot;VF0&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/vf0.csv&quot;, &quot;name&quot;: &quot;Kolsass&quot;, &quot;latitude&quot;: 47.305, &quot;longitude&quot;: 11.622,&#10;            &quot;height&quot;: 545},&#10;    &quot;SF8&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/sf8.csv&quot;, &quot;name&quot;: &quot;Terfens&quot;, &quot;latitude&quot;: 47.326, &quot;longitude&quot;: 11.652,&#10;            &quot;height&quot;: 575},&#10;    &quot;SF1&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/sf1.csv&quot;, &quot;name&quot;: &quot;Eggen&quot;, &quot;latitude&quot;: 47.317, &quot;longitude&quot;: 11.616,&#10;            &quot;height&quot;: 829},&#10;    &quot;NF10&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/nf10.csv&quot;, &quot;name&quot;: &quot;Weerberg&quot;, &quot;latitude&quot;: 47.300, &quot;longitude&quot;: 11.673,&#10;             &quot;height&quot;: 930},&#10;    &quot;NF27&quot;: {&quot;filepath&quot;: f&quot;{ibox_folder}/nf27.csv&quot;, &quot;name&quot;: &quot;Hochhaeuser&quot;, &quot;latitude&quot;: 47.288, &quot;longitude&quot;: 11.631,&#10;             &quot;height&quot;: 1009}}&#10;&#10;# dict with infos about EC stations&#10;ec_station_names = {1: {&quot;name&quot;: &quot;Patsch_EC_South&quot;, &quot;lat&quot;: 47.209068, &quot;lon&quot;: 11.411932},&#10;                    0: {&quot;name&quot;: &quot;Innsbruck_Airport_EC_West&quot;, &quot;lat&quot;: 47.255375, &quot;lon&quot;: 11.342832},&#10;                    2: {&quot;name&quot;: &quot;Thaur_EC_East&quot;, &quot;lat&quot;: 47.281335, &quot;lon&quot;: 11.474532},&#10;                    3: {&quot;name&quot;: &quot;IAO_Centre_Innsbruck_EC_Center&quot;, &quot;lat&quot;: 47.264035, &quot;lon&quot;: 11.385707}}&#10;&#10;# variables, units 2D AROME&#10;variables_units_2D_AROME = {'hfs': 'W/m²',  # Sensible heat flux at the surface&#10;                            'hgt': 'm',  # Surface geopotential height&#10;                            'lfs': 'W/m²',  # Latent heat flux at the surface&#10;                            'lwd': 'W/m²',  # Longwave incoming radiation at the surface&#10;                            'lwnet': 'W/m²',  # Longwave net radiation at the surface&#10;                            'lwu': 'W/m²',  # Longwave outgoing radiation at the surface (derived: lwnet - lwd)&#10;                            'pre': 'kg/m²',  # Surface precipitation (same as mm)&#10;                            'ps': 'Pa',  # Surface pressure&#10;                            'swd': 'W/m²',  # Shortwave incoming radiation at the surface&#10;                            'swnet': 'W/m²',  # Shortwave net radiation at the surface&#10;                            'swu': 'W/m²',  # Shortwave reflected radiation at the surface (derived: swnet - swd)&#10;                            'tsk': 'K'  # Surface temperature (Oberflächentemperatur)&#10;                            }&#10;&#10;# variables, units 3D AROME&#10;variables_units_3D_AROME = {'ciwc': 'kg/kg',  # Specific cloud ice water content&#10;                            'clwc': 'kg/kg',  # Specific cloud liquid water content&#10;                            'p': 'Pa',  # Pressure&#10;                            'q': 'kg/kg',  # Specific humidity&#10;                            'th': 'K',  # Potential temperature&#10;                            'tke': 'm²/s²',  # Turbulent kinetic energy&#10;                            'u': 'm/s',  # Zonal wind component&#10;                            'v': 'm/s',  # Meridional wind component&#10;                            'w': 'm/s',  # Vertical wind velocity&#10;                            'z': 'm',  # Geopotential height&#10;                            }&#10;&#10;# Define colors for the cities, used e.g. in temperature timeseries&#10;cities = {&#10;    'Innsbruck Uni': {'lon': 11.384167, 'lat': 47.259998, 'csv': innsbruck_uni_zamg, 'color': &quot;red&quot;, 'hoehe': 578, },&#10;    'Kufstein': {'lon': 12.162778, 'lat': 47.575279, 'csv': kufstein_zamg, 'color': &quot;blue&quot;, 'hoehe': 490, },&#10;    'Innsbruck Airport': {'lat': 47.2598, 'lon': 11.3553, 'csv': innsbruck_airport_zamg, 'color': &quot;green&quot;,&#10;                          'hoehe': 578, },&#10;    'Jenbach': {'lat': 47.388889, 'lon': 11.758056, 'csv': jenbach_zamg, 'color': &quot;gray&quot;, 'hoehe': 530, },&#10;    'Rinn': {'lat': 47.249168, 'lon': 11.503889, 'csv': rinn_zamg, 'color': &quot;purple&quot;, 'hoehe': 924},&#10;    'Muenchen': {'lat': 48.149723, 'lon': 11.540523, 'color': &quot;orange&quot;, 'hoehe': 521, 'csv': munchen_zamg&#10;                 # Replace 'munchen_zamg' with the actual path to your CSV file if you have data for München&#10;                 }}&#10;&#10;# information about MOMMA stations&#10;MOMMA_stations = {&quot;0&quot;: &quot;Völs&quot;, &quot;1&quot;: &quot;Innsbruck_Bergisel&quot;, &quot;2&quot;: &quot;Patsch_Pfaffenbichl&quot;, &quot;3&quot;: &quot;Innsbruck_Ölberg&quot;,&#10;                  &quot;4&quot;: &quot;Innsbruck_Hotel Hilton&quot;, &quot;5&quot;: &quot;Innsbruck_Saggen_Kettenbrücke&quot;, &quot;6&quot;: &quot;Volders&quot;,&#10;                  &quot;7&quot;: &quot;Unterperfuss&quot;, &quot;8&quot;: &quot;Inzing_Zirl_Modellflugplatz&quot;}&#10;&#10;MOMMA_stations_PM = {&#10;    &quot;PM02&quot;: {&quot;name&quot;: &quot;Völs&quot;, &quot;latitude&quot;: 47.2614791608, &quot;longitude&quot;: 11.3117537274, &quot;height&quot;: 583, &quot;key&quot;: 0},&#10;    &quot;PM03&quot;: {&quot;name&quot;: &quot;Innsbruck_Bergisel&quot;, &quot;latitude&quot;: 47.2472604421, &quot;longitude&quot;: 11.3986000093, &quot;height&quot;: 726,&#10;             &quot;key&quot;: 1},&#10;    &quot;PM04&quot;: {&quot;name&quot;: &quot;Patsch_Pfaffenbichl&quot;, &quot;latitude&quot;: 47.21030188, &quot;longitude&quot;: 11.4105114057, &quot;height&quot;: 983,&#10;             &quot;key&quot;: 2},&#10;    &quot;PM05&quot;: {&quot;name&quot;: &quot;Innsbruck_Ölberg&quot;, &quot;latitude&quot;: 47.2784241867, &quot;longitude&quot;: 11.3902967638, &quot;height&quot;: 722,&#10;             &quot;key&quot;: 3},&#10;    &quot;PM06&quot;: {&quot;name&quot;: &quot;Innsbruck_Hotel Hilton&quot;, &quot;latitude&quot;: 47.2620425014, &quot;longitude&quot;: 11.3959606669, &quot;height&quot;: 629,&#10;             &quot;key&quot;: 4},&#10;    &quot;PM07&quot;: {&quot;name&quot;: &quot;Innsbruck_Saggen_Kettenbrücke&quot;, &quot;latitude&quot;: 47.2787431973, &quot;longitude&quot;: 11.4123320657,&#10;             &quot;height&quot;: 569, &quot;key&quot;: 5},&#10;    &quot;PM08&quot;: {&quot;name&quot;: &quot;Volders&quot;, &quot;latitude&quot;: 47.2930516284, &quot;longitude&quot;: 11.5697988436, &quot;height&quot;: 552, &quot;key&quot;: 6},&#10;    &quot;PM09&quot;: {&quot;name&quot;: &quot;Unterperfuss&quot;, &quot;latitude&quot;: 47.2615210341, &quot;longitude&quot;: 11.2607050096, &quot;height&quot;: 594, &quot;key&quot;: 7},&#10;    &quot;PM10&quot;: {&quot;name&quot;: &quot;Inzing_Zirl_Modellflugplatz&quot;, &quot;latitude&quot;: 47.2744017492, &quot;longitude&quot;: 11.2143291427,&#10;             &quot;height&quot;: 597, &quot;key&quot;: 8}}&#10;&#10;# units of lidar observations&#10;vars_lidar = {'u': 'm/s', 'v': 'm/s', 'w': 'm/s', 'ff': 'm/s', 'dd': 'degree'}&#10;&#10;# hatpro height information&#10;hatpro_vertical_levels = {&#10;    &quot;height_name&quot;: [&quot;V01&quot;, &quot;V02&quot;, &quot;V03&quot;, &quot;V04&quot;, &quot;V05&quot;, &quot;V06&quot;, &quot;V07&quot;, &quot;V08&quot;, &quot;V09&quot;, &quot;V10&quot;, &quot;V11&quot;, &quot;V12&quot;, &quot;V13&quot;, &quot;V14&quot;,&#10;                    &quot;V15&quot;, &quot;V16&quot;, &quot;V17&quot;, &quot;V18&quot;, &quot;V19&quot;, &quot;V20&quot;, &quot;V21&quot;, &quot;V22&quot;, &quot;V23&quot;, &quot;V24&quot;, &quot;V25&quot;, &quot;V26&quot;, &quot;V27&quot;, &quot;V28&quot;,&#10;                    &quot;V29&quot;, &quot;V30&quot;, &quot;V31&quot;, &quot;V32&quot;, &quot;V33&quot;, &quot;V34&quot;, &quot;V35&quot;, &quot;V36&quot;, &quot;V37&quot;, &quot;V38&quot;, &quot;V39&quot;],&#10;    &quot;height&quot;: [&quot;0&quot;, &quot;10&quot;, &quot;30&quot;, &quot;50&quot;, &quot;75&quot;, &quot;100&quot;, &quot;125&quot;, &quot;150&quot;, &quot;200&quot;, &quot;250&quot;, &quot;325&quot;, &quot;400&quot;, &quot;475&quot;, &quot;550&quot;, &quot;625&quot;, &quot;700&quot;,&#10;               &quot;800&quot;, &quot;900&quot;, &quot;1000&quot;, &quot;1150&quot;, &quot;1300&quot;, &quot;1450&quot;, &quot;1600&quot;, &quot;1800&quot;, &quot;2000&quot;, &quot;2200&quot;, &quot;2500&quot;, &quot;2800&quot;, &quot;3100&quot;,&#10;               &quot;3500&quot;, &quot;3900&quot;, &quot;4400&quot;, &quot;5000&quot;, &quot;5600&quot;, &quot;6200&quot;, &quot;7000&quot;, &quot;8000&quot;, &quot;9000&quot;, &quot;10000&quot;]}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/plot_timeseries.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/plot_timeseries.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;This script is used to plot the time series of the vertical distribution of potential temperature for all models.&#10;problem: vertical coordinate is not the same for all models =&gt; use pressure?&#10;&quot;&quot;&quot;&#10;&#10;# Fix for OpenMP duplicate library error on Windows&#10;import os&#10;os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'&#10;&#10;import sys&#10;sys.path.append(&quot;D:/MSc_Arbeit/model_comparison_codes&quot;)&#10;import importlib&#10;import read_in_arome&#10;import read_icon_model_3D&#10;import read_ukmo&#10;# importlib.reload(read_icon_model_3D)&#10;import read_wrf_helen&#10;importlib.reload(read_in_arome)&#10;import confg&#10;import xarray as xr&#10;import numpy as np&#10;import matplotlib&#10;import matplotlib.pyplot as plt&#10;import pandas as pd&#10;from colorspace import diverging_hcl&#10;&#10;&#10;&#10;def plot_pot_temp_time_contours(pot_temp, model=&quot;AROME&quot;):&#10;    &quot;&quot;&quot;&#10;    plot pot temp time &amp; height series for all models. HATPRO was interpolated to AROME levels &amp; it's pressure is used&#10;    to compute pot temp.&#10;    thin 1 K pot temp contour lines, thick 5 K pot temp contour lines and red/blue shading for the 1/2 hrly&#10;    warming/cooling in pot temp is plotted&#10;&#10;    :param pot_temp:&#10;    :param model:&#10;    :return:&#10;    &quot;&quot;&quot;&#10;    fig, ax = plt.subplots(figsize=(12, 6))&#10;&#10;    vmin, vmax = -2, 2  # uniform colorbar&#10;    levels = np.arange(vmin, vmax + 0.5, 0.5)&#10;    # limit the time range for the plot&#10;    start_time = pd.to_datetime('2017-10-15 13:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    end_time = pd.to_datetime('2017-10-16 12:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    # pot_temp = pot_temp.sel(time=slice(start_time, end_time))&#10;&#10;    # Plot the filled contours&#10;    contourf = (pot_temp.diff(&quot;time&quot;, n=1) * 2).plot.contourf(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;, levels=levels, cmap=pal1.cmap(),&#10;                                                   add_colorbar=False, vmin=vmin, vmax=vmax)&#10;&#10;    # Plot the contour lines&#10;    contour1 = pot_temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;,&#10;                                     levels=np.arange(np.round(pot_temp.min()), np.round(pot_temp.max()), 1),&#10;                                     colors='black', linewidths=0.5)   #.isel(time=slice(1, 100))&#10;    contour5 = pot_temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;, levels=np.arange(290, np.round(pot_temp.max()), 5),&#10;                                     colors='black', linewidths=1.5)  #.isel(time=slice(1, 100))&#10;    ax.clabel(contour5)&#10;&#10;    ax.set_xlim(start_time, end_time)&#10;    # Add a colorbar&#10;    cbar = plt.colorbar(contourf, ax=ax)&#10;    cbar.set_label('K hr$^{-1}$')&#10;&#10;    ax.set_title(model + &quot; potential temp time series&quot;)&#10;    if model ==  &quot;HATPRO&quot;:&#10;        ax.set_ylabel(f&quot;height [m]&quot;)&#10;    elif model == &quot;ICON&quot; or model == &quot;ICON2TE&quot;:&#10;        ax.set_ylabel(f&quot;geometric height [m]&quot;)&#10;    else:&#10;        ax.set_ylabel(f&quot;geopotential height [m]&quot;)&#10;    ax.set_xlabel(&quot;&quot;)&#10;&#10;    plt.savefig(confg.dir_PLOTS + model + f&quot;_pot_temp_timeseries_{interface_height}_ibk.png&quot;, dpi=500)&#10;&#10;&#10;def plot_temp_time_contours(temp, model=&quot;AROME&quot;):&#10;    &quot;&quot;&quot;&#10;    plot temp over time &amp; height for all models incl HATPRO.&#10;    :param temp:&#10;    :param model:&#10;    :return:&#10;    &quot;&quot;&quot;&#10;&#10;    fig, ax = plt.subplots(figsize=(12, 6))&#10;&#10;    vmin, vmax = -1.5, 1.5  # uniform colorbar&#10;    levels = np.arange(vmin, vmax + 0.3, 0.3)&#10;&#10;    start_time = pd.to_datetime('2017-10-15 14:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    end_time = pd.to_datetime('2017-10-16 12:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    # temp = temp.sel(time=slice(start_time, end_time))&#10;&#10;    # Plot the filled contours&#10;    contourf = temp.diff(&quot;time&quot;).plot.contourf(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;, levels=levels, cmap=pal1.cmap(),&#10;                                                   add_colorbar=False, vmin=-2, vmax=2)&#10;&#10;    # Plot the contour lines&#10;    contour1 = temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;,&#10;                                                                    levels=np.arange(np.round(temp.min()),&#10;                                                                                     np.round(temp.max()), 1),&#10;                                                                    colors='black', linewidths=0.5)   #.isel(time=slice(1, 100))&#10;    contour5 = temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;,&#10;                                                                    levels=np.arange(-50, np.round(temp.max()), 5),&#10;                                                                    colors='black', linewidths=1.5)  #.isel(time=slice(1, 100))&#10;    ax.clabel(contour5)&#10;&#10;    ax.set_xlim(start_time, end_time)&#10;    # Add a colorbar&#10;    cbar = plt.colorbar(contourf, ax=ax)&#10;    cbar.set_label('K hr$^{-1}$')&#10;    ax.set_title(model + &quot; temp time series&quot;)&#10;    if model ==  &quot;HATPRO&quot;:&#10;        ax.set_ylabel(f&quot;height [m]&quot;)&#10;    else:&#10;        ax.set_ylabel(f&quot;geopotential height [m]&quot;)&#10;    ax.set_xlabel(&quot;&quot;)&#10;    plt.savefig(confg.dir_PLOTS + model + &quot;_temp_timeseries_ibk.png&quot;, dpi=300)&#10;    plt.show()&#10;&#10;&#10;def plot_arome():&#10;    # arome = read_in_arome.read_in_arome_fixed_point(lat=lat_ibk, lon=lon_ibk, )&#10;    # arome = read_in_arome.read_3D_variables_AROME(variables=[&quot;p&quot;, &quot;th&quot;, &quot;z&quot;], method=&quot;sel&quot;, lat=lat_ibk, lon=lon_ibk)&#10;    # pot_temp = arome.th.isel(nz=np.arange(40, 90))&#10;&#10;    arome = xr.open_dataset(confg.model_folder + &quot;/AROME/&quot; + &quot;AROME_temp_timeseries_ibk.nc&quot;)&#10;    pot_temp = arome.th.where(arome[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;    plot_pot_temp_time_contours(pot_temp, model=&quot;AROME&quot;)&#10;&#10;    # temp = arome.temperature.where(arome.height &lt;= 4000, drop=True)  # tried with normal temp, but you don't see much...&#10;    # plot_temp_time_contours(temp, model=&quot;AROME&quot;)&#10;&#10;def plot_icon():&#10;    &quot;&quot;&quot;icon15 = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=15, hours=np.arange(14, 23), lon=lon_ibk, lat=lat_ibk, variant=&quot;ICON&quot;)&#10;    icon16 = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=16, hours=np.arange(0, 9), lon=lon_ibk, lat=lat_ibk, variant=&quot;ICON&quot;)&#10;    variables = [&quot;th&quot;, &quot;temp&quot;, &quot;z_ifc&quot;]  # &quot;temp&quot;, &quot;pres&quot;, &quot;u&quot;, &quot;v&quot;, &quot;w&quot;,&#10;    icon = xr.concat([icon15[variables], icon16[variables]], dim=&quot;time&quot;)&quot;&quot;&quot;&#10;    icon = xr.open_dataset(confg.icon_folder_3D + &quot;/ICON_temp_timeseries_ibk.nc&quot;)&#10;    pot_temp = icon.th.where(icon[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;    plot_pot_temp_time_contours(pot_temp, model=&quot;ICON&quot;)&#10;&#10;def plot_icon2te():&#10;    &quot;&quot;&quot;icon15_2te = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=15, hours=range(12, 24), lon=lon_ibk,&#10;                                                                         lat=lat_ibk, variant=&quot;ICON2TE&quot;)&#10;    icon16_2te = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=16, hours=range(00, 13), lon=lon_ibk,&#10;                                                                         lat=lat_ibk, variant=&quot;ICON2TE&quot;)&#10;    variables = [&quot;th&quot;, &quot;temp&quot;]  # [&quot;temp&quot;, &quot;pressure&quot;, &quot;pres&quot;, &quot;u&quot;, &quot;v&quot;, &quot;w&quot;]&#10;    icon2te = xr.concat([icon15_2te[variables], icon16_2te[variables]], dim=&quot;time&quot;)&#10;    icon2te_pot_temp = icon2te.th.isel(height=np.arange(40, 90))&quot;&quot;&quot;&#10;&#10;    icon_2te = xr.open_dataset(confg.icon2TE_folder_3D + &quot;/ICON_2TE_latlon_temp_timeseries_ibk.nc&quot;)&#10;    icon_2te_pot_temp = icon_2te.th.where(icon_2te[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;    plot_pot_temp_time_contours(pot_temp=icon_2te_pot_temp, model=&quot;ICON2TE_latlon&quot;)&#10;&#10;def plot_ukmo():&#10;    um = xr.open_dataset(confg.ukmo_folder + &quot;/UKMO_temp_timeseries_ibk.nc&quot;)&#10;    um_pot_temp = um.th.where(um[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;&#10;    plot_pot_temp_time_contours(pot_temp=um_pot_temp, model=&quot;UKMO&quot;)&#10;&#10;def plot_wrf():&#10;    # wrf = read_wrf_helen.read_wrf_fixed_point(lat=lat_ibk, lon=lon_ibk)&#10;    # wrf_pot_temp = wrf.th.isel(height=slice(0, 50))&#10;&#10;    wrf = xr.open_dataset(confg.wrf_folder + &quot;/WRF_temp_timeseries_ibk.nc&quot;)&#10;    wrf_pot_temp = wrf.th.where(wrf[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;&#10;    plot_pot_temp_time_contours(pot_temp=wrf_pot_temp, model=&quot;WRF&quot;)&#10;&#10;&#10;def plot_hatpro():&#10;    # hatpro = xr.open_dataset(f&quot;{confg.hatpro_folder}/hatpro_merged.nc&quot;)&#10;    # hatpro_temp = hatpro[&quot;temperature&quot;].sel(height=slice(0, 4400))  # select up to 4.400 m&#10;    # plot_temp_time_contours(temp=hatpro_temp, model=&quot;HATPRO&quot;)&#10;    # hatpro&#10;&#10;    # try with hatpro interpolated data&#10;    hatpro = xr.open_dataset(f&quot;{confg.hatpro_folder}/hatpro_interpolated_arome.nc&quot;)&#10;    hatpro_pot_temp = hatpro[&quot;th&quot;].where(hatpro[&quot;height&quot;] &lt;= interface_height, drop=True)  # hatpro[&quot;th&quot;].sel(height=slice(0, 4400))  # select up to 4.400 m&#10;    plot_pot_temp_time_contours(pot_temp=hatpro_pot_temp, model=&quot;HATPRO&quot;)&#10;&#10;if __name__ == '__main__':&#10;    lat_ibk = 47.259998&#10;    lon_ibk = 11.384167&#10;    interface_height = 2500  # what is max height that should be plotted?&#10;    pal1 = diverging_hcl(palette=&quot;Blue-Red 2&quot;)&#10;&#10;    matplotlib.use('Qt5Agg')  # Use the Qt5Agg backend for interactive plotting&#10;&#10;    #plot_arome()&#10;&#10;    plot_icon()&#10;    plot_icon2te()&#10;&#10;    #plot_ukmo()&#10;    #plot_wrf()&#10;    #plot_hatpro()&#10;    plt.show()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;This script is used to plot the time series of the vertical distribution of potential temperature for all models.&#10;problem: vertical coordinate is not the same for all models =&gt; use pressure?&#10;&quot;&quot;&quot;&#10;&#10;# Fix for OpenMP duplicate library error on Windows&#10;import os&#10;os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'&#10;&#10;import sys&#10;sys.path.append(&quot;D:/MSc_Arbeit/model_comparison_codes&quot;)&#10;import importlib&#10;import read_in_arome&#10;import read_icon_model_3D&#10;import read_ukmo&#10;# importlib.reload(read_icon_model_3D)&#10;import read_wrf_helen&#10;importlib.reload(read_in_arome)&#10;import confg&#10;import xarray as xr&#10;import numpy as np&#10;import matplotlib&#10;import matplotlib.pyplot as plt&#10;import pandas as pd&#10;from colorspace import diverging_hcl&#10;&#10;&#10;&#10;def plot_pot_temp_time_contours(pot_temp, model=&quot;AROME&quot;):&#10;    &quot;&quot;&quot;&#10;    plot pot temp time &amp; height series for all models. HATPRO was interpolated to AROME levels &amp; it's pressure is used&#10;    to compute pot temp.&#10;    thin 1 K pot temp contour lines, thick 5 K pot temp contour lines and red/blue shading for the 1/2 hrly&#10;    warming/cooling in pot temp is plotted&#10;&#10;    :param pot_temp:&#10;    :param model:&#10;    :return:&#10;    &quot;&quot;&quot;&#10;    fig, ax = plt.subplots(figsize=(12, 6))&#10;&#10;    vmin, vmax = -2, 2  # uniform colorbar&#10;    levels = np.arange(vmin, vmax + 0.5, 0.5)&#10;    # limit the time range for the plot&#10;    start_time = pd.to_datetime('2017-10-15 13:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    end_time = pd.to_datetime('2017-10-16 12:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    # pot_temp = pot_temp.sel(time=slice(start_time, end_time))&#10;&#10;    # Plot the filled contours&#10;    contourf = (pot_temp.diff(&quot;time&quot;, n=1) * 2).plot.contourf(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;, levels=levels, cmap=pal1.cmap(),&#10;                                                   add_colorbar=False, vmin=vmin, vmax=vmax)&#10;&#10;    # Plot the contour lines&#10;    contour1 = pot_temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;,&#10;                                     levels=np.arange(np.round(pot_temp.min()), np.round(pot_temp.max()), 1),&#10;                                     colors='black', linewidths=0.5)   #.isel(time=slice(1, 100))&#10;    contour5 = pot_temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;, levels=np.arange(290, np.round(pot_temp.max()), 5),&#10;                                     colors='black', linewidths=1.5)  #.isel(time=slice(1, 100))&#10;    ax.clabel(contour5)&#10;&#10;    ax.set_xlim(start_time, end_time)&#10;    # Add a colorbar&#10;    cbar = plt.colorbar(contourf, ax=ax)&#10;    cbar.set_label('K hr$^{-1}$')&#10;&#10;    ax.set_title(model + &quot; potential temp time series&quot;)&#10;    if model ==  &quot;HATPRO&quot;:&#10;        ax.set_ylabel(f&quot;height [m]&quot;)&#10;    elif model == &quot;ICON&quot; or model == &quot;ICON2TE&quot;:&#10;        ax.set_ylabel(f&quot;geometric height [m]&quot;)&#10;    else:&#10;        ax.set_ylabel(f&quot;geopotential height [m]&quot;)&#10;    ax.set_xlabel(&quot;&quot;)&#10;&#10;    plt.savefig(confg.dir_PLOTS + model + f&quot;_pot_temp_timeseries_{interface_height}_ibk.png&quot;, dpi=500)&#10;&#10;&#10;def plot_temp_time_contours(temp, model=&quot;AROME&quot;):&#10;    &quot;&quot;&quot;&#10;    plot temp over time &amp; height for all models incl HATPRO.&#10;    :param temp:&#10;    :param model:&#10;    :return:&#10;    &quot;&quot;&quot;&#10;&#10;    fig, ax = plt.subplots(figsize=(12, 6))&#10;&#10;    vmin, vmax = -1.5, 1.5  # uniform colorbar&#10;    levels = np.arange(vmin, vmax + 0.3, 0.3)&#10;&#10;    start_time = pd.to_datetime('2017-10-15 14:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    end_time = pd.to_datetime('2017-10-16 12:00:00', format='%Y-%m-%d %H:%M:%S')&#10;    # temp = temp.sel(time=slice(start_time, end_time))&#10;&#10;    # Plot the filled contours&#10;    contourf = temp.diff(&quot;time&quot;).plot.contourf(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;, levels=levels, cmap=pal1.cmap(),&#10;                                                   add_colorbar=False, vmin=-2, vmax=2)&#10;&#10;    # Plot the contour lines&#10;    contour1 = temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;,&#10;                                                                    levels=np.arange(np.round(temp.min()),&#10;                                                                                     np.round(temp.max()), 1),&#10;                                                                    colors='black', linewidths=0.5)   #.isel(time=slice(1, 100))&#10;    contour5 = temp.plot.contour(ax=ax, x=&quot;time&quot;, y=&quot;height&quot;,&#10;                                                                    levels=np.arange(-50, np.round(temp.max()), 5),&#10;                                                                    colors='black', linewidths=1.5)  #.isel(time=slice(1, 100))&#10;    ax.clabel(contour5)&#10;&#10;    ax.set_xlim(start_time, end_time)&#10;    # Add a colorbar&#10;    cbar = plt.colorbar(contourf, ax=ax)&#10;    cbar.set_label('K hr$^{-1}$')&#10;    ax.set_title(model + &quot; temp time series&quot;)&#10;    if model ==  &quot;HATPRO&quot;:&#10;        ax.set_ylabel(f&quot;height [m]&quot;)&#10;    else:&#10;        ax.set_ylabel(f&quot;geopotential height [m]&quot;)&#10;    ax.set_xlabel(&quot;&quot;)&#10;    plt.savefig(confg.dir_PLOTS + model + &quot;_temp_timeseries_ibk.png&quot;, dpi=300)&#10;    plt.show()&#10;&#10;&#10;def plot_arome():&#10;    # arome = read_in_arome.read_in_arome_fixed_point(lat=lat_ibk, lon=lon_ibk, )&#10;    # arome = read_in_arome.read_3D_variables_AROME(variables=[&quot;p&quot;, &quot;th&quot;, &quot;z&quot;], method=&quot;sel&quot;, lat=lat_ibk, lon=lon_ibk)&#10;    # pot_temp = arome.th.isel(nz=np.arange(40, 90))&#10;&#10;    arome = xr.open_dataset(confg.model_folder + &quot;/AROME/&quot; + &quot;AROME_temp_timeseries_ibk.nc&quot;)&#10;    pot_temp = arome.th.where(arome[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;    plot_pot_temp_time_contours(pot_temp, model=&quot;AROME&quot;)&#10;&#10;    # temp = arome.temperature.where(arome.height &lt;= 4000, drop=True)  # tried with normal temp, but you don't see much...&#10;    # plot_temp_time_contours(temp, model=&quot;AROME&quot;)&#10;&#10;def plot_icon():&#10;    &quot;&quot;&quot;icon15 = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=15, hours=np.arange(14, 23), lon=lon_ibk, lat=lat_ibk, variant=&quot;ICON&quot;)&#10;    icon16 = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=16, hours=np.arange(0, 9), lon=lon_ibk, lat=lat_ibk, variant=&quot;ICON&quot;)&#10;    variables = [&quot;th&quot;, &quot;temp&quot;, &quot;z_ifc&quot;]  # &quot;temp&quot;, &quot;pres&quot;, &quot;u&quot;, &quot;v&quot;, &quot;w&quot;,&#10;    icon = xr.concat([icon15[variables], icon16[variables]], dim=&quot;time&quot;)&quot;&quot;&quot;&#10;    icon = xr.open_dataset(confg.icon_folder_3D + &quot;/ICON_temp_timeseries_ibk.nc&quot;)&#10;    pot_temp = icon.th.where(icon[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;    plot_pot_temp_time_contours(pot_temp, model=&quot;ICON&quot;)&#10;&#10;def plot_icon2te():&#10;    &quot;&quot;&quot;icon15_2te = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=15, hours=range(12, 24), lon=lon_ibk,&#10;                                                                         lat=lat_ibk, variant=&quot;ICON2TE&quot;)&#10;    icon16_2te = read_icon_model_3D.read_icon_fixed_point_multiple_hours(day=16, hours=range(00, 13), lon=lon_ibk,&#10;                                                                         lat=lat_ibk, variant=&quot;ICON2TE&quot;)&#10;    variables = [&quot;th&quot;, &quot;temp&quot;]  # [&quot;temp&quot;, &quot;pressure&quot;, &quot;pres&quot;, &quot;u&quot;, &quot;v&quot;, &quot;w&quot;]&#10;    icon2te = xr.concat([icon15_2te[variables], icon16_2te[variables]], dim=&quot;time&quot;)&#10;    icon2te_pot_temp = icon2te.th.isel(height=np.arange(40, 90))&quot;&quot;&quot;&#10;&#10;    icon_2te = xr.open_dataset(confg.icon2TE_folder_3D + &quot;/ICON_2TE_latlon_temp_timeseries_ibk.nc&quot;)&#10;    icon_2te_pot_temp = icon_2te.th.where(icon_2te[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;    plot_pot_temp_time_contours(pot_temp=icon_2te_pot_temp, model=&quot;ICON2TE_latlon&quot;)&#10;&#10;def plot_ukmo():&#10;    um = xr.open_dataset(confg.ukmo_folder + &quot;/UKMO_temp_timeseries_ibk.nc&quot;)&#10;    um_pot_temp = um.th.where(um[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;&#10;    plot_pot_temp_time_contours(pot_temp=um_pot_temp, model=&quot;UKMO&quot;)&#10;&#10;def plot_wrf():&#10;    # wrf = read_wrf_helen.read_wrf_fixed_point(lat=lat_ibk, lon=lon_ibk)&#10;    # wrf_pot_temp = wrf.th.isel(height=slice(0, 50))&#10;&#10;    wrf = xr.open_dataset(confg.wrf_folder + &quot;/WRF_temp_timeseries_ibk.nc&quot;)&#10;    wrf_pot_temp = wrf.th.where(wrf[&quot;height&quot;] &lt;= interface_height, drop=True)&#10;&#10;    plot_pot_temp_time_contours(pot_temp=wrf_pot_temp, model=&quot;WRF&quot;)&#10;&#10;&#10;def plot_hatpro():&#10;    # hatpro = xr.open_dataset(f&quot;{confg.hatpro_folder}/hatpro_merged.nc&quot;)&#10;    # hatpro_temp = hatpro[&quot;temperature&quot;].sel(height=slice(0, 4400))  # select up to 4.400 m&#10;    # plot_temp_time_contours(temp=hatpro_temp, model=&quot;HATPRO&quot;)&#10;    # hatpro&#10;&#10;    # try with hatpro interpolated data&#10;    hatpro = xr.open_dataset(f&quot;{confg.hatpro_folder}/hatpro_interpolated_arome.nc&quot;)&#10;    hatpro_pot_temp = hatpro[&quot;th&quot;].where(hatpro[&quot;height&quot;] &lt;= interface_height, drop=True)  # hatpro[&quot;th&quot;].sel(height=slice(0, 4400))  # select up to 4.400 m&#10;    plot_pot_temp_time_contours(pot_temp=hatpro_pot_temp, model=&quot;HATPRO&quot;)&#10;&#10;if __name__ == '__main__':&#10;    lat_ibk = 47.259998&#10;    lon_ibk = 11.384167&#10;    interface_height = 2500  # what is max height that should be plotted?&#10;    pal1 = diverging_hcl(palette=&quot;Blue-Red 2&quot;)&#10;&#10;    matplotlib.use('Qt5Agg')  # Use the Qt5Agg backend for interactive plotting&#10;&#10;    #plot_arome()&#10;&#10;    plot_icon()&#10;    plot_icon2te()&#10;&#10;    #plot_ukmo()&#10;    #plot_wrf()&#10;    #plot_hatpro()&#10;    plt.show()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>