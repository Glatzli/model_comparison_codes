{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b564110",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../confg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf09857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read in the 3D ICON Model\n",
    "\n",
    "functions used from outside:\n",
    "- read_icon_fixed_point() need dask to read it in, a lot of RAM used\n",
    "- read_icon_fixed_point_and_time()\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import metpy.calc as mpcalc\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from metpy.units import units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d957d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_icon_fixed_point(nearest_grid_cell, day=16):\n",
    "    \"\"\"\n",
    "    Reads ICON 3D datasets for a given day and a given grid cell\n",
    "    NOTE: Since the files are large we need dask to not get a overflow in RAM used\n",
    "\n",
    "    Parameters:\n",
    "    - nearest_grid_cell: The index of the nearest cell\n",
    "\n",
    "    Returns:\n",
    "    - Combined xarray dataset along dimensions, with selected ICON variables.\n",
    "    \"\"\"\n",
    "    if day not in [15, 16]:\n",
    "        raise ValueError(\"Only October day 15 or 16 is available!\")\n",
    "\n",
    "    file_pattern = f'ICON_2TE_BLM-GUF_20171015T1200Z_CAP02_2D-3D_10min_1km_all_201710{str(day)}T????00Z.nc'\n",
    "\n",
    "    # Preprocess function to select data at a specific location\n",
    "    def _preprocess(x):\n",
    "        return x.isel(ncells=nearest_grid_cell)\n",
    "\n",
    "    # Use open_mfdataset with the partial function as a preprocess argument\n",
    "    partial_func = partial(_preprocess)\n",
    "\n",
    "    # Load and concatenate datasets automatically by coordinates\n",
    "    ds = xr.open_mfdataset(\n",
    "        f\"{icon2TE_folder_3D}/{file_pattern}\",\n",
    "        combine='by_coords',\n",
    "        preprocess=partial_func\n",
    "    )\n",
    "\n",
    "    # Handling 'z_ifc' to include only in the first dataset\n",
    "    if 'z_ifc' in ds.variables:\n",
    "        z_ifc = ds['z_ifc'].isel(time=0).expand_dims('time')  # Get 'z_ifc' from the first time point\n",
    "        ds = ds.drop_vars('z_ifc', errors='ignore')  # Drop 'z_ifc' from all datasets\n",
    "        ds = ds.assign({'z_ifc': z_ifc})  # Reassign 'z_ifc' only for the first time point\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de118f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Mal \", dims=[\"height\"] entfernt\"\n",
    "def convert_calc_variables(df):\n",
    "    \"\"\"\n",
    "    Converts and calculates meteorological variables for a xarray Dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: A xarray Dataset containing the columns 'p' for pressure in Pa\n",
    "          and 'th' for potential temperature in Kelvin.\n",
    "\n",
    "    Returns:\n",
    "    - A xarray Dataset with the original data and new columns:\n",
    "      'pressure' in hPa and 'temperature' in degrees Celsius.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert pressure from Pa to hPa\n",
    "    df['pressure'] = df['pres'] / 100.0\n",
    "    p = df['pressure'].values * units.hPa\n",
    "\n",
    "    # Calculate temperature from potential temperature\n",
    "    temp_C = df[\"temp\"] - 273.15\n",
    "    df[\"temperature\"] = temp_C\n",
    "\n",
    "    # calculate specific + relativ humidity\n",
    "    temp_values = temp_C.values * units.degC\n",
    "    specific_humidity = df[\"qv\"].values * 1000 * units(\"g/kg\")\n",
    "    df['specific_humidity'] = xr.DataArray(data=specific_humidity.magnitude)\n",
    "\n",
    "    # the variables that go into mpcalc have to Arrays (Quantitys) without Dimension (important to take .values before)\n",
    "    relative_humidity = mpcalc.relative_humidity_from_specific_humidity(p, temp_values, specific_humidity).to('percent')\n",
    "    df['relative_humidity'] = xr.DataArray(data=relative_humidity.magnitude)\n",
    "\n",
    "    # calculate dewpoint\n",
    "    rh_values = df[\"relative_humidity\"].values * units.percent\n",
    "    dewpoint = mpcalc.dewpoint_from_relative_humidity(temp_values, rh_values).to(\"degC\")\n",
    "    df['dewpoint'] = xr.DataArray(data=dewpoint.magnitude)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ed9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_index_old(ds_icon, my_lon, my_lat):\n",
    "    \"\"\"Deprecated\n",
    "\n",
    "    Old version to find min index, by haversine takes too much time (3 seconds)\"\"\"\n",
    "    lon_rad = np.radians(my_lon)\n",
    "    lat_rad = np.radians(my_lat)\n",
    "\n",
    "    def haversine(lon1, lat1, lon2, lat2):\n",
    "        # Radius of the Earth in kilometers\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.asin(math.sqrt(a))\n",
    "        r = 6371  # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "        return c * r\n",
    "\n",
    "    # Apply Haversine to calculate distances to all points\n",
    "    distances = xr.apply_ufunc(\n",
    "        haversine,\n",
    "        lon_rad,\n",
    "        lat_rad,\n",
    "        ds_icon.clon,\n",
    "        ds_icon.clat,\n",
    "        vectorize=True\n",
    "    )\n",
    "\n",
    "    # Find the index of the minimum distance\n",
    "    min_idx = distances.argmin()\n",
    "    return min_idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25074946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_index(ds_icon, my_lon, my_lat):\n",
    "    \"\"\"Distances are relatively short where the curvature of the Earth can be neglected (fast 0.04 seconds)\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians for calculation\n",
    "    lon_rad = np.radians(my_lon)\n",
    "    lat_rad = np.radians(my_lat)\n",
    "\n",
    "    lon_diff_squared = (ds_icon.clon - lon_rad) ** 2\n",
    "    lat_diff_squared = (ds_icon.clat - lat_rad) ** 2\n",
    "\n",
    "    # Sum the squared differences to get squared Euclidean distances\n",
    "    squared_distances = lon_diff_squared + lat_diff_squared\n",
    "\n",
    "    # Find the index of the minimum squared distance\n",
    "    min_idx = squared_distances.argmin()\n",
    "    return min_idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0606bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_icon2TE_fixed_point_and_time(day, hour, my_lon, my_lat):\n",
    "    \"\"\"Read Icon 3D model at a fixed point and a fixed time\"\"\"\n",
    "    if day not in [15, 16]:\n",
    "        raise ValueError(\"Only October day 15 or 16 is available!\")\n",
    "\n",
    "    formatted_hour = f\"{hour:02d}\"\n",
    "\n",
    "    day = str(day)\n",
    "    icon_file = f'ICON_2TE_BLM-GUF_20171015T1200Z_CAP02_2D-3D_10min_1km_all_201710{day}T{formatted_hour}0000Z.nc'\n",
    "\n",
    "    # -- Getting data\n",
    "    ds_icon = xr.open_dataset(f\"{icon2TE_folder_3D}/{icon_file}\")\n",
    "    \n",
    "    min_idx = find_min_index(ds_icon, my_lon, my_lat)\n",
    "\n",
    "    nearest_data = ds_icon.isel(ncells=min_idx).isel(time=0)\n",
    "\n",
    "    return convert_calc_variables(nearest_data)  # calculate temp, pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d38b37",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\MSc_Arbeit\\\\ICON2TE\\\\ICON_2TE_BLM-GUF_20171015T1200Z_CAP02_2D-3D_10min_1km_all_20171016T120000Z.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\file_manager.py:211\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[39m, in \u001b[36mLRUCache.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m._cache.move_to_end(key)\n",
      "\u001b[31mKeyError\u001b[39m: [<class 'netCDF4._netCDF4.Dataset'>, ('D:\\\\MSc_Arbeit\\\\ICON2TE\\\\ICON_2TE_BLM-GUF_20171015T1200Z_CAP02_2D-3D_10min_1km_all_20171016T120000Z.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '187c7d0f-4c10-4572-88ce-a9930b411fd5']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df_nearest2 = \u001b[43mread_icon2TE_fixed_point_and_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhour\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_lon\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m11.4011756\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mmy_lat\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m47.266076\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df_nearest2)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#     print(df_nearest.data_vars)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#     df = read_icon_lidar()\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#     print(df.load())\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m#Example usage with specified longitude and latitude\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mread_icon2TE_fixed_point_and_time\u001b[39m\u001b[34m(day, hour, my_lon, my_lat)\u001b[39m\n\u001b[32m      9\u001b[39m icon_file = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mICON_2TE_BLM-GUF_20171015T1200Z_CAP02_2D-3D_10min_1km_all_201710\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mT\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformatted_hour\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m0000Z.nc\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# -- Getting data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m ds_icon = \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43micon2TE_folder_3D\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43micon_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m min_idx = find_min_index(ds_icon, my_lon, my_lat)\n\u001b[32m     16\u001b[39m nearest_data = ds_icon.isel(ncells=min_idx).isel(time=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\api.py:686\u001b[39m, in \u001b[36mopen_dataset\u001b[39m\u001b[34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[39m\n\u001b[32m    674\u001b[39m decoders = _resolve_decoders_kwargs(\n\u001b[32m    675\u001b[39m     decode_cf,\n\u001b[32m    676\u001b[39m     open_backend_dataset_parameters=backend.open_dataset_parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    682\u001b[39m     decode_coords=decode_coords,\n\u001b[32m    683\u001b[39m )\n\u001b[32m    685\u001b[39m overwrite_encoded_chunks = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33moverwrite_encoded_chunks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m backend_ds = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    692\u001b[39m ds = _dataset_from_backend_dataset(\n\u001b[32m    693\u001b[39m     backend_ds,\n\u001b[32m    694\u001b[39m     filename_or_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    704\u001b[39m     **kwargs,\n\u001b[32m    705\u001b[39m )\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:666\u001b[39m, in \u001b[36mNetCDF4BackendEntrypoint.open_dataset\u001b[39m\u001b[34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, auto_complex, lock, autoclose)\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_dataset\u001b[39m(\n\u001b[32m    645\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    646\u001b[39m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m | os.PathLike[Any] | ReadBuffer | AbstractDataStore,\n\u001b[32m   (...)\u001b[39m\u001b[32m    663\u001b[39m     autoclose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    664\u001b[39m ) -> Dataset:\n\u001b[32m    665\u001b[39m     filename_or_obj = _normalize_path(filename_or_obj)\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     store = \u001b[43mNetCDF4DataStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m     store_entrypoint = StoreBackendEntrypoint()\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:452\u001b[39m, in \u001b[36mNetCDF4DataStore.open\u001b[39m\u001b[34m(cls, filename, mode, format, group, clobber, diskless, persist, auto_complex, lock, lock_maker, autoclose)\u001b[39m\n\u001b[32m    448\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauto_complex\u001b[39m\u001b[33m\"\u001b[39m] = auto_complex\n\u001b[32m    449\u001b[39m manager = CachingFileManager(\n\u001b[32m    450\u001b[39m     netCDF4.Dataset, filename, mode=mode, kwargs=kwargs\n\u001b[32m    451\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:393\u001b[39m, in \u001b[36mNetCDF4DataStore.__init__\u001b[39m\u001b[34m(self, manager, group, mode, lock, autoclose)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28mself\u001b[39m._group = group\n\u001b[32m    392\u001b[39m \u001b[38;5;28mself\u001b[39m._mode = mode\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28mself\u001b[39m.format = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mds\u001b[49m.data_model\n\u001b[32m    394\u001b[39m \u001b[38;5;28mself\u001b[39m._filename = \u001b[38;5;28mself\u001b[39m.ds.filepath()\n\u001b[32m    395\u001b[39m \u001b[38;5;28mself\u001b[39m.is_remote = is_remote_uri(\u001b[38;5;28mself\u001b[39m._filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:461\u001b[39m, in \u001b[36mNetCDF4DataStore.ds\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:455\u001b[39m, in \u001b[36mNetCDF4DataStore._acquire\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[39m, in \u001b[36mCachingFileManager.acquire_context\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    198\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     file, cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\msc\\Lib\\site-packages\\xarray\\backends\\file_manager.py:217\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    215\u001b[39m     kwargs = kwargs.copy()\n\u001b[32m    216\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._mode\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode == \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28mself\u001b[39m._mode = \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\netCDF4\\\\_netCDF4.pyx:2521\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Dataset.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\netCDF4\\\\_netCDF4.pyx:2158\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'D:\\\\MSc_Arbeit\\\\ICON2TE\\\\ICON_2TE_BLM-GUF_20171015T1200Z_CAP02_2D-3D_10min_1km_all_20171016T120000Z.nc'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_nearest2 = read_icon2TE_fixed_point_and_time(day=16, hour=12, my_lon=11.4011756,\n",
    "                                                 my_lat=47.266076)\n",
    "\n",
    "    print(df_nearest2)\n",
    "\n",
    "#     print(df_nearest.data_vars)\n",
    "#     df = read_icon_lidar()\n",
    "\n",
    "#     df = read_icon_lidar(lon=station_files_zamg[\"IAO\"][\"lon\"], lat=station_files_zamg[\"IAO\"][\"lat\"])\n",
    "#     print(df)\n",
    "#     d = read_icon3D_2(day=16)\n",
    "#     print(d)\n",
    "#     df = read_icon_fixed_point(d.load(), my_lon=station_files_zamg[\"IAO\"][\"lon\"], my_lat=station_files_zamg[\"IAO\"][\"lat\"])\n",
    "#     print(df.load())\n",
    "    #Example usage with specified longitude and latitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e2173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459fe4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
